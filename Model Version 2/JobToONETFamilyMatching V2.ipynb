{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PURPOSE OF THIS NOTEBOOK\n",
    "This is the base code to write the functions to extract the raw text from resumes and append to our dataframe. \n",
    "\n",
    "TODO: Take the functions into a .py folder and use it as a script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zaffa\\AppData\\Local\\Temp\\ipykernel_23308\\478442376.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from pathlib import Path\n",
    "from torch import cuda\n",
    "import torch\n",
    "\n",
    "from sklearn import metrics\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up for GPU \n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Goal\n",
    "\n",
    "The goal is to train a custom BERT model to attempt to label each incoming job title to their proper ONET code. ONET (Occupational Information Network) is a free database that serves as a standardized taxonomy for jobs. Each job has a respective standardized name and code associated with it. This will make extracting skills quite easy if we can corrrectly translate job titles to the proper ONET code. Using BERT, we can tokenize the job titles and match them with the database of common job titles for each ONET code. For this first version I will be leaving out the actual ONET job names from the training data to compare later with an updated dataset. More information about ONET can be found here: https://www.onetonline.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the train/test Data. \n",
    "test_df = pd.read_csv(\"../Data/TestingData.csv\")\n",
    "train_df = pd.read_csv(\"../Data/Training_Data.csv\")\n",
    "label_df = pd.read_csv(\"../Data/label_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reported_Jobs</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General and Operations Managers</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marketing Managers</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public Relations Managers</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Financial Managers</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Treasurers and Controllers</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Reported_Jobs   \n",
       "0  General and Operations Managers  \\\n",
       "1               Marketing Managers   \n",
       "2        Public Relations Managers   \n",
       "3               Financial Managers   \n",
       "4       Treasurers and Controllers   \n",
       "\n",
       "                                               Label  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the test data incoming is correct\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reported_Jobs</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Farmers, Ranchers, and Other Agricultural Mana...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supply Chain Planning Manager</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales Vice President (Sales VP)</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Special Programs Director</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Offshore Wind Operations Manager</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Reported_Jobs   \n",
       "0  Farmers, Ranchers, and Other Agricultural Mana...  \\\n",
       "1                      Supply Chain Planning Manager   \n",
       "2                    Sales Vice President (Sales VP)   \n",
       "3                          Special Programs Director   \n",
       "4                   Offshore Wind Operations Manager   \n",
       "\n",
       "                                               Label  \n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the training data incoming is correct \n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Label'] = train_df['Label'].apply(lambda s: [float(x.strip(' []')) for x in s.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Label'] = test_df['Label'].apply(lambda s: [float(x.strip(' []')) for x in s.split(',')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of the tokenizer\n",
    "\n",
    "From looking at the reference code, I've learned that we need to follow these steps: \n",
    "1. Start with a train test split. **70% for the training data**, I will do the split based on the **70%** of each reported job title/ONET pairing.\n",
    "    - Given the refernece notebook uses a dictionary as the input data and we are working with a dataframe instead, some major changes will be needed to be made in order for this to work. I don't think this would be difficult at all. Just need to translate the dictionary work to the dataframe. **I also need to confirm if the model input requires a list, dict, or dataframe object.**\n",
    "2. Run the tokenizer on the training set \n",
    "3. Set up the model training and evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 175\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 2e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by tokenizing the data.\n",
    "# Will be using the class statment and slowly converting it for our needs \n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.reported_jobs = dataframe.Reported_Jobs\n",
    "        self.targets = self.data.Label\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reported_jobs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        reported_job = str(self.reported_jobs[index])\n",
    "        reported_job = \" \".join(reported_job.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            reported_job,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the tokenizer and shaping the dataframes for the model\n",
    "train_set = CustomDataset(train_df, tokenizer, MAX_LEN)\n",
    "test_set = CustomDataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the train and test parameters \n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0}\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "               'shuffle': True,\n",
    "               'num_workers': 0}\n",
    "\n",
    "training_loader = DataLoader(train_set, **train_params)\n",
    "testing_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=22, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creatring the custom model\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        # Defining the layers\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 22)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1 = self.l1(ids, attention_mask=mask, token_type_ids=token_type_ids)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output_3 = self.l3(output_2)\n",
    "        return output_3\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss= loss_fn(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch : {epoch}, Loss: {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _,data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e638af2230dc4335805af20fd1720ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0, Loss: 0.6686908602714539\n",
      "Epoch : 0, Loss: 0.5447896718978882\n",
      "Epoch : 0, Loss: 0.42241349816322327\n",
      "Epoch : 0, Loss: 0.3650408685207367\n",
      "Epoch : 0, Loss: 0.31953945755958557\n",
      "Epoch : 0, Loss: 0.2928646206855774\n",
      "Epoch : 0, Loss: 0.25403958559036255\n",
      "Epoch : 0, Loss: 0.234996497631073\n",
      "Epoch : 0, Loss: 0.21643680334091187\n",
      "Epoch : 0, Loss: 0.22354571521282196\n",
      "Epoch : 0, Loss: 0.22798292338848114\n",
      "Epoch : 0, Loss: 0.21032732725143433\n",
      "Epoch : 0, Loss: 0.21259330213069916\n",
      "Epoch : 0, Loss: 0.19307245314121246\n",
      "Epoch : 0, Loss: 0.17451123893260956\n",
      "Epoch : 0, Loss: 0.19305419921875\n",
      "Epoch : 0, Loss: 0.2032051980495453\n",
      "Epoch : 0, Loss: 0.1881873905658722\n",
      "Epoch : 0, Loss: 0.17739985883235931\n",
      "Epoch : 0, Loss: 0.16108138859272003\n",
      "Epoch : 0, Loss: 0.18719148635864258\n",
      "Epoch : 0, Loss: 0.14387093484401703\n",
      "Epoch : 0, Loss: 0.15119338035583496\n",
      "Epoch : 0, Loss: 0.1782234013080597\n",
      "Epoch : 0, Loss: 0.1684022694826126\n",
      "Epoch : 0, Loss: 0.15253818035125732\n",
      "Epoch : 0, Loss: 0.17267084121704102\n",
      "Epoch : 0, Loss: 0.12169556319713593\n",
      "Epoch : 0, Loss: 0.1376441866159439\n",
      "Epoch : 0, Loss: 0.16105122864246368\n",
      "Epoch : 0, Loss: 0.1524125039577484\n",
      "Epoch : 0, Loss: 0.15867623686790466\n",
      "Epoch : 0, Loss: 0.1141180470585823\n",
      "Epoch : 0, Loss: 0.14253416657447815\n",
      "Epoch : 0, Loss: 0.1775803565979004\n",
      "Epoch : 0, Loss: 0.15349991619586945\n",
      "Epoch : 0, Loss: 0.12754976749420166\n",
      "Epoch : 0, Loss: 0.13910087943077087\n",
      "Epoch : 0, Loss: 0.11777997016906738\n",
      "Epoch : 0, Loss: 0.1631414294242859\n",
      "Epoch : 0, Loss: 0.12743251025676727\n",
      "Epoch : 0, Loss: 0.11361104249954224\n",
      "Epoch : 0, Loss: 0.1290440857410431\n",
      "Epoch : 0, Loss: 0.14093679189682007\n",
      "Epoch : 0, Loss: 0.15244963765144348\n",
      "Epoch : 0, Loss: 0.12266086786985397\n",
      "Epoch : 0, Loss: 0.13886399567127228\n",
      "Epoch : 0, Loss: 0.1475842446088791\n",
      "Epoch : 0, Loss: 0.16000767052173615\n",
      "Epoch : 0, Loss: 0.13913477957248688\n",
      "Epoch : 0, Loss: 0.1446288377046585\n",
      "Epoch : 0, Loss: 0.1421031504869461\n",
      "Epoch : 0, Loss: 0.09300252050161362\n",
      "Epoch : 0, Loss: 0.13920308649539948\n",
      "Epoch : 0, Loss: 0.14822548627853394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87db31cb469400eb43723a5e1e25b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.2526326986490799\n",
      "F1 Score (Micro) = 0.3770589402659258\n",
      "F1 Score (Macro) = 0.03822582106663401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f26ba91eb224b8499f204f2b45bcb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss: 0.10584739595651627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss: 0.1333741545677185\n",
      "Epoch : 1, Loss: 0.14192163944244385\n",
      "Epoch : 1, Loss: 0.14890508353710175\n",
      "Epoch : 1, Loss: 0.1291889250278473\n",
      "Epoch : 1, Loss: 0.10933613777160645\n",
      "Epoch : 1, Loss: 0.14017923176288605\n",
      "Epoch : 1, Loss: 0.1458941251039505\n",
      "Epoch : 1, Loss: 0.10056950896978378\n",
      "Epoch : 1, Loss: 0.1523650735616684\n",
      "Epoch : 1, Loss: 0.1110098585486412\n",
      "Epoch : 1, Loss: 0.12292682379484177\n",
      "Epoch : 1, Loss: 0.1019427552819252\n",
      "Epoch : 1, Loss: 0.13870756328105927\n",
      "Epoch : 1, Loss: 0.14965379238128662\n",
      "Epoch : 1, Loss: 0.1458628624677658\n",
      "Epoch : 1, Loss: 0.13705217838287354\n",
      "Epoch : 1, Loss: 0.11750668287277222\n",
      "Epoch : 1, Loss: 0.1185394898056984\n",
      "Epoch : 1, Loss: 0.1036681979894638\n",
      "Epoch : 1, Loss: 0.1021561250090599\n",
      "Epoch : 1, Loss: 0.10996544361114502\n",
      "Epoch : 1, Loss: 0.1260419338941574\n",
      "Epoch : 1, Loss: 0.13893774151802063\n",
      "Epoch : 1, Loss: 0.13745731115341187\n",
      "Epoch : 1, Loss: 0.15739741921424866\n",
      "Epoch : 1, Loss: 0.08578529208898544\n",
      "Epoch : 1, Loss: 0.11236222833395004\n",
      "Epoch : 1, Loss: 0.08885542303323746\n",
      "Epoch : 1, Loss: 0.1349285989999771\n",
      "Epoch : 1, Loss: 0.11202501505613327\n",
      "Epoch : 1, Loss: 0.10755311697721481\n",
      "Epoch : 1, Loss: 0.14034298062324524\n",
      "Epoch : 1, Loss: 0.11510316282510757\n",
      "Epoch : 1, Loss: 0.14439982175827026\n",
      "Epoch : 1, Loss: 0.06499685347080231\n",
      "Epoch : 1, Loss: 0.10427653044462204\n",
      "Epoch : 1, Loss: 0.1313532143831253\n",
      "Epoch : 1, Loss: 0.12131840735673904\n",
      "Epoch : 1, Loss: 0.12787047028541565\n",
      "Epoch : 1, Loss: 0.09630393981933594\n",
      "Epoch : 1, Loss: 0.15583790838718414\n",
      "Epoch : 1, Loss: 0.11051739752292633\n",
      "Epoch : 1, Loss: 0.12308333814144135\n",
      "Epoch : 1, Loss: 0.09529801458120346\n",
      "Epoch : 1, Loss: 0.06805939972400665\n",
      "Epoch : 1, Loss: 0.10064923018217087\n",
      "Epoch : 1, Loss: 0.09564618766307831\n",
      "Epoch : 1, Loss: 0.1051323264837265\n",
      "Epoch : 1, Loss: 0.145389586687088\n",
      "Epoch : 1, Loss: 0.09388496726751328\n",
      "Epoch : 1, Loss: 0.05081025883555412\n",
      "Epoch : 1, Loss: 0.1367359310388565\n",
      "Epoch : 1, Loss: 0.08899607509374619\n",
      "Epoch : 1, Loss: 0.09063546359539032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b721470687f44d4298ffbd4adfff61b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.42915647271566854\n",
      "F1 Score (Micro) = 0.5632416585229653\n",
      "F1 Score (Macro) = 0.24839081800700286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82217bebbc284f84b10e153f01ce7fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Loss: 0.0866217240691185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2, Loss: 0.08872959017753601\n",
      "Epoch : 2, Loss: 0.10517007857561111\n",
      "Epoch : 2, Loss: 0.07339112460613251\n",
      "Epoch : 2, Loss: 0.11943019926548004\n",
      "Epoch : 2, Loss: 0.09750065207481384\n",
      "Epoch : 2, Loss: 0.0764087662100792\n",
      "Epoch : 2, Loss: 0.07401484251022339\n",
      "Epoch : 2, Loss: 0.06779317557811737\n",
      "Epoch : 2, Loss: 0.08068372309207916\n",
      "Epoch : 2, Loss: 0.08178167045116425\n",
      "Epoch : 2, Loss: 0.12070535868406296\n",
      "Epoch : 2, Loss: 0.07698087394237518\n",
      "Epoch : 2, Loss: 0.1087341234087944\n",
      "Epoch : 2, Loss: 0.1160891056060791\n",
      "Epoch : 2, Loss: 0.06481651961803436\n",
      "Epoch : 2, Loss: 0.11378546804189682\n",
      "Epoch : 2, Loss: 0.07132886350154877\n",
      "Epoch : 2, Loss: 0.1165822222828865\n",
      "Epoch : 2, Loss: 0.11953126639127731\n",
      "Epoch : 2, Loss: 0.08413666486740112\n",
      "Epoch : 2, Loss: 0.1145290955901146\n",
      "Epoch : 2, Loss: 0.05900145694613457\n",
      "Epoch : 2, Loss: 0.09721916913986206\n",
      "Epoch : 2, Loss: 0.1213502362370491\n",
      "Epoch : 2, Loss: 0.07682787626981735\n",
      "Epoch : 2, Loss: 0.1185837835073471\n",
      "Epoch : 2, Loss: 0.0690431147813797\n",
      "Epoch : 2, Loss: 0.09165970236063004\n",
      "Epoch : 2, Loss: 0.08733879029750824\n",
      "Epoch : 2, Loss: 0.06890644878149033\n",
      "Epoch : 2, Loss: 0.08566877245903015\n",
      "Epoch : 2, Loss: 0.0934731736779213\n",
      "Epoch : 2, Loss: 0.08163096755743027\n",
      "Epoch : 2, Loss: 0.11237053573131561\n",
      "Epoch : 2, Loss: 0.05722789466381073\n",
      "Epoch : 2, Loss: 0.06808311492204666\n",
      "Epoch : 2, Loss: 0.1038074642419815\n",
      "Epoch : 2, Loss: 0.09495367854833603\n",
      "Epoch : 2, Loss: 0.10772887617349625\n",
      "Epoch : 2, Loss: 0.06481191515922546\n",
      "Epoch : 2, Loss: 0.07968655973672867\n",
      "Epoch : 2, Loss: 0.05966056138277054\n",
      "Epoch : 2, Loss: 0.05963360518217087\n",
      "Epoch : 2, Loss: 0.06707065552473068\n",
      "Epoch : 2, Loss: 0.08479392528533936\n",
      "Epoch : 2, Loss: 0.09214767813682556\n",
      "Epoch : 2, Loss: 0.14722883701324463\n",
      "Epoch : 2, Loss: 0.10218719393014908\n",
      "Epoch : 2, Loss: 0.07081244140863419\n",
      "Epoch : 2, Loss: 0.09447310119867325\n",
      "Epoch : 2, Loss: 0.06992895901203156\n",
      "Epoch : 2, Loss: 0.06364356726408005\n",
      "Epoch : 2, Loss: 0.10990452766418457\n",
      "Epoch : 2, Loss: 0.05938734859228134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d60b59378640b286a348f6d739613d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.5549941495585576\n",
      "F1 Score (Micro) = 0.6632766566025743\n",
      "F1 Score (Macro) = 0.40368226500262167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5921e097b6754846be8d32557f8f2e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Loss: 0.12481033056974411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3, Loss: 0.05862743407487869\n",
      "Epoch : 3, Loss: 0.06797752529382706\n",
      "Epoch : 3, Loss: 0.08147172629833221\n",
      "Epoch : 3, Loss: 0.10499338805675507\n",
      "Epoch : 3, Loss: 0.0676903948187828\n",
      "Epoch : 3, Loss: 0.10231716185808182\n",
      "Epoch : 3, Loss: 0.07861845195293427\n",
      "Epoch : 3, Loss: 0.12955033779144287\n",
      "Epoch : 3, Loss: 0.11028876155614853\n",
      "Epoch : 3, Loss: 0.08262502402067184\n",
      "Epoch : 3, Loss: 0.10061492025852203\n",
      "Epoch : 3, Loss: 0.05643723905086517\n",
      "Epoch : 3, Loss: 0.09342116117477417\n",
      "Epoch : 3, Loss: 0.057388242334127426\n",
      "Epoch : 3, Loss: 0.0799834206700325\n",
      "Epoch : 3, Loss: 0.06149311736226082\n",
      "Epoch : 3, Loss: 0.0299521591514349\n",
      "Epoch : 3, Loss: 0.11865001916885376\n",
      "Epoch : 3, Loss: 0.0835433378815651\n",
      "Epoch : 3, Loss: 0.08054811507463455\n",
      "Epoch : 3, Loss: 0.07810869067907333\n",
      "Epoch : 3, Loss: 0.06415827572345734\n",
      "Epoch : 3, Loss: 0.09694630652666092\n",
      "Epoch : 3, Loss: 0.06617781519889832\n",
      "Epoch : 3, Loss: 0.06394994258880615\n",
      "Epoch : 3, Loss: 0.06521438807249069\n",
      "Epoch : 3, Loss: 0.08313343673944473\n",
      "Epoch : 3, Loss: 0.09695208072662354\n",
      "Epoch : 3, Loss: 0.08433860540390015\n",
      "Epoch : 3, Loss: 0.0628553032875061\n",
      "Epoch : 3, Loss: 0.0586940161883831\n",
      "Epoch : 3, Loss: 0.05725904181599617\n",
      "Epoch : 3, Loss: 0.06886167824268341\n",
      "Epoch : 3, Loss: 0.042347535490989685\n",
      "Epoch : 3, Loss: 0.1475035846233368\n",
      "Epoch : 3, Loss: 0.14114327728748322\n",
      "Epoch : 3, Loss: 0.09954333305358887\n",
      "Epoch : 3, Loss: 0.059134405106306076\n",
      "Epoch : 3, Loss: 0.061720799654722214\n",
      "Epoch : 3, Loss: 0.056648582220077515\n",
      "Epoch : 3, Loss: 0.10724140703678131\n",
      "Epoch : 3, Loss: 0.06284952163696289\n",
      "Epoch : 3, Loss: 0.07208342850208282\n",
      "Epoch : 3, Loss: 0.09475823491811752\n",
      "Epoch : 3, Loss: 0.09784046560525894\n",
      "Epoch : 3, Loss: 0.059788625687360764\n",
      "Epoch : 3, Loss: 0.07521053403615952\n",
      "Epoch : 3, Loss: 0.02768995426595211\n",
      "Epoch : 3, Loss: 0.06117900460958481\n",
      "Epoch : 3, Loss: 0.09063974022865295\n",
      "Epoch : 3, Loss: 0.11602157354354858\n",
      "Epoch : 3, Loss: 0.06796973943710327\n",
      "Epoch : 3, Loss: 0.07498031854629517\n",
      "Epoch : 3, Loss: 0.046845171600580215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdebfb711489438db38d96241badf6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6316349324539943\n",
      "F1 Score (Micro) = 0.7133719708116874\n",
      "F1 Score (Macro) = 0.539965859211822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3389936a5964495bfa0dfc2f68a1dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Loss: 0.04813079163432121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4, Loss: 0.07462497055530548\n",
      "Epoch : 4, Loss: 0.05825631320476532\n",
      "Epoch : 4, Loss: 0.05869974568486214\n",
      "Epoch : 4, Loss: 0.07546848058700562\n",
      "Epoch : 4, Loss: 0.07165487110614777\n",
      "Epoch : 4, Loss: 0.07774392515420914\n",
      "Epoch : 4, Loss: 0.09435395896434784\n",
      "Epoch : 4, Loss: 0.08512712270021439\n",
      "Epoch : 4, Loss: 0.12367433309555054\n",
      "Epoch : 4, Loss: 0.049812350422143936\n",
      "Epoch : 4, Loss: 0.06067901849746704\n",
      "Epoch : 4, Loss: 0.044189855456352234\n",
      "Epoch : 4, Loss: 0.11724110692739487\n",
      "Epoch : 4, Loss: 0.06187888979911804\n",
      "Epoch : 4, Loss: 0.03579708933830261\n",
      "Epoch : 4, Loss: 0.06115950271487236\n",
      "Epoch : 4, Loss: 0.04962105676531792\n",
      "Epoch : 4, Loss: 0.03714162856340408\n",
      "Epoch : 4, Loss: 0.08429281413555145\n",
      "Epoch : 4, Loss: 0.04057425260543823\n",
      "Epoch : 4, Loss: 0.08863595873117447\n",
      "Epoch : 4, Loss: 0.08615809679031372\n",
      "Epoch : 4, Loss: 0.09494340419769287\n",
      "Epoch : 4, Loss: 0.062093835324048996\n",
      "Epoch : 4, Loss: 0.06085510924458504\n",
      "Epoch : 4, Loss: 0.09643158316612244\n",
      "Epoch : 4, Loss: 0.05524700507521629\n",
      "Epoch : 4, Loss: 0.06711307913064957\n",
      "Epoch : 4, Loss: 0.024684613570570946\n",
      "Epoch : 4, Loss: 0.06387630850076675\n",
      "Epoch : 4, Loss: 0.05480748042464256\n",
      "Epoch : 4, Loss: 0.054165344685316086\n",
      "Epoch : 4, Loss: 0.08840210735797882\n",
      "Epoch : 4, Loss: 0.03459889814257622\n",
      "Epoch : 4, Loss: 0.023011937737464905\n",
      "Epoch : 4, Loss: 0.027180006727576256\n",
      "Epoch : 4, Loss: 0.07963797450065613\n",
      "Epoch : 4, Loss: 0.09196653217077255\n",
      "Epoch : 4, Loss: 0.049182016402482986\n",
      "Epoch : 4, Loss: 0.09314445406198502\n",
      "Epoch : 4, Loss: 0.05358019843697548\n",
      "Epoch : 4, Loss: 0.04301402345299721\n",
      "Epoch : 4, Loss: 0.06473114341497421\n",
      "Epoch : 4, Loss: 0.05638093873858452\n",
      "Epoch : 4, Loss: 0.06365151703357697\n",
      "Epoch : 4, Loss: 0.03596201539039612\n",
      "Epoch : 4, Loss: 0.08338340371847153\n",
      "Epoch : 4, Loss: 0.06822764873504639\n",
      "Epoch : 4, Loss: 0.11418427526950836\n",
      "Epoch : 4, Loss: 0.08385686576366425\n",
      "Epoch : 4, Loss: 0.10863517224788666\n",
      "Epoch : 4, Loss: 0.08268342167139053\n",
      "Epoch : 4, Loss: 0.04722142964601517\n",
      "Epoch : 4, Loss: 0.07519583404064178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070649c4ce9d42f180649805353095ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6678544835655781\n",
      "F1 Score (Micro) = 0.736317532905344\n",
      "F1 Score (Macro) = 0.593889388422442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6659014f3e4f1aa1b51ec46ce63125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Loss: 0.07493830472230911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5, Loss: 0.06486809253692627\n",
      "Epoch : 5, Loss: 0.0611177496612072\n",
      "Epoch : 5, Loss: 0.12714795768260956\n",
      "Epoch : 5, Loss: 0.04701622575521469\n",
      "Epoch : 5, Loss: 0.09151645749807358\n",
      "Epoch : 5, Loss: 0.0845445841550827\n",
      "Epoch : 5, Loss: 0.1213182806968689\n",
      "Epoch : 5, Loss: 0.052728936076164246\n",
      "Epoch : 5, Loss: 0.11373208463191986\n",
      "Epoch : 5, Loss: 0.06702401489019394\n",
      "Epoch : 5, Loss: 0.04152834042906761\n",
      "Epoch : 5, Loss: 0.05679120868444443\n",
      "Epoch : 5, Loss: 0.051721177995204926\n",
      "Epoch : 5, Loss: 0.05802449584007263\n",
      "Epoch : 5, Loss: 0.08071964979171753\n",
      "Epoch : 5, Loss: 0.02931107208132744\n",
      "Epoch : 5, Loss: 0.03188570216298103\n",
      "Epoch : 5, Loss: 0.11129927635192871\n",
      "Epoch : 5, Loss: 0.043235909193754196\n",
      "Epoch : 5, Loss: 0.06112082675099373\n",
      "Epoch : 5, Loss: 0.063640296459198\n",
      "Epoch : 5, Loss: 0.07106975466012955\n",
      "Epoch : 5, Loss: 0.09380599856376648\n",
      "Epoch : 5, Loss: 0.031011691316962242\n",
      "Epoch : 5, Loss: 0.07550403475761414\n",
      "Epoch : 5, Loss: 0.052711308002471924\n",
      "Epoch : 5, Loss: 0.027133481577038765\n",
      "Epoch : 5, Loss: 0.07012072950601578\n",
      "Epoch : 5, Loss: 0.022256996482610703\n",
      "Epoch : 5, Loss: 0.10714248567819595\n",
      "Epoch : 5, Loss: 0.09217119216918945\n",
      "Epoch : 5, Loss: 0.12421027570962906\n",
      "Epoch : 5, Loss: 0.04839075729250908\n",
      "Epoch : 5, Loss: 0.06898883730173111\n",
      "Epoch : 5, Loss: 0.06862311065196991\n",
      "Epoch : 5, Loss: 0.06099962443113327\n",
      "Epoch : 5, Loss: 0.03783648833632469\n",
      "Epoch : 5, Loss: 0.01920531503856182\n",
      "Epoch : 5, Loss: 0.040276866406202316\n",
      "Epoch : 5, Loss: 0.050282154232263565\n",
      "Epoch : 5, Loss: 0.10686226934194565\n",
      "Epoch : 5, Loss: 0.033844515681266785\n",
      "Epoch : 5, Loss: 0.038062531501054764\n",
      "Epoch : 5, Loss: 0.023299846798181534\n",
      "Epoch : 5, Loss: 0.06651240587234497\n",
      "Epoch : 5, Loss: 0.087070532143116\n",
      "Epoch : 5, Loss: 0.08703652769327164\n",
      "Epoch : 5, Loss: 0.04085247963666916\n",
      "Epoch : 5, Loss: 0.04757998511195183\n",
      "Epoch : 5, Loss: 0.04029541090130806\n",
      "Epoch : 5, Loss: 0.05771443620324135\n",
      "Epoch : 5, Loss: 0.046564456075429916\n",
      "Epoch : 5, Loss: 0.08163782209157944\n",
      "Epoch : 5, Loss: 0.08981551975011826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a205862204344f9e906b6c65a1f1d748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.702318902244442\n",
      "F1 Score (Micro) = 0.7537041258263051\n",
      "F1 Score (Macro) = 0.6456416818260474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5d2496f1f44a76bac5e4c035093950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Loss: 0.0902947336435318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6, Loss: 0.06470391899347305\n",
      "Epoch : 6, Loss: 0.08065144717693329\n",
      "Epoch : 6, Loss: 0.017553387209773064\n",
      "Epoch : 6, Loss: 0.05971129983663559\n",
      "Epoch : 6, Loss: 0.03487444296479225\n",
      "Epoch : 6, Loss: 0.03389224410057068\n",
      "Epoch : 6, Loss: 0.09390590339899063\n",
      "Epoch : 6, Loss: 0.07787589728832245\n",
      "Epoch : 6, Loss: 0.03394738584756851\n",
      "Epoch : 6, Loss: 0.052915871143341064\n",
      "Epoch : 6, Loss: 0.05124155804514885\n",
      "Epoch : 6, Loss: 0.03786084055900574\n",
      "Epoch : 6, Loss: 0.05505726858973503\n",
      "Epoch : 6, Loss: 0.019739573821425438\n",
      "Epoch : 6, Loss: 0.06575560569763184\n",
      "Epoch : 6, Loss: 0.0859568864107132\n",
      "Epoch : 6, Loss: 0.0792660117149353\n",
      "Epoch : 6, Loss: 0.04520321637392044\n",
      "Epoch : 6, Loss: 0.10894232988357544\n",
      "Epoch : 6, Loss: 0.0576501227915287\n",
      "Epoch : 6, Loss: 0.08960884809494019\n",
      "Epoch : 6, Loss: 0.049418896436691284\n",
      "Epoch : 6, Loss: 0.09461373090744019\n",
      "Epoch : 6, Loss: 0.17497463524341583\n",
      "Epoch : 6, Loss: 0.009149097837507725\n",
      "Epoch : 6, Loss: 0.01173790916800499\n",
      "Epoch : 6, Loss: 0.062085412442684174\n",
      "Epoch : 6, Loss: 0.06576266139745712\n",
      "Epoch : 6, Loss: 0.03177172690629959\n",
      "Epoch : 6, Loss: 0.030232902616262436\n",
      "Epoch : 6, Loss: 0.05275491252541542\n",
      "Epoch : 6, Loss: 0.047378022223711014\n",
      "Epoch : 6, Loss: 0.020761331543326378\n",
      "Epoch : 6, Loss: 0.0784248486161232\n",
      "Epoch : 6, Loss: 0.10026788711547852\n",
      "Epoch : 6, Loss: 0.07754384726285934\n",
      "Epoch : 6, Loss: 0.03308974206447601\n",
      "Epoch : 6, Loss: 0.0844721794128418\n",
      "Epoch : 6, Loss: 0.05738712474703789\n",
      "Epoch : 6, Loss: 0.1617807149887085\n",
      "Epoch : 6, Loss: 0.05830491706728935\n",
      "Epoch : 6, Loss: 0.058532580733299255\n",
      "Epoch : 6, Loss: 0.05771768093109131\n",
      "Epoch : 6, Loss: 0.06965890526771545\n",
      "Epoch : 6, Loss: 0.03786708787083626\n",
      "Epoch : 6, Loss: 0.09059248864650726\n",
      "Epoch : 6, Loss: 0.05438262224197388\n",
      "Epoch : 6, Loss: 0.07669882476329803\n",
      "Epoch : 6, Loss: 0.0649031549692154\n",
      "Epoch : 6, Loss: 0.043959349393844604\n",
      "Epoch : 6, Loss: 0.04371852055191994\n",
      "Epoch : 6, Loss: 0.08023174852132797\n",
      "Epoch : 6, Loss: 0.04749858006834984\n",
      "Epoch : 6, Loss: 0.018326088786125183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567a3d85987b4a2e8fdf39cfed56b867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.724444208062972\n",
      "F1 Score (Micro) = 0.767816479716623\n",
      "F1 Score (Macro) = 0.7139180539775412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ad9682f2fa4d9589bc768b94af3689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Loss: 0.10280066728591919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7, Loss: 0.04903590306639671\n",
      "Epoch : 7, Loss: 0.04251061752438545\n",
      "Epoch : 7, Loss: 0.031259093433618546\n",
      "Epoch : 7, Loss: 0.028683487325906754\n",
      "Epoch : 7, Loss: 0.049132395535707474\n",
      "Epoch : 7, Loss: 0.08842789381742477\n",
      "Epoch : 7, Loss: 0.0376494824886322\n",
      "Epoch : 7, Loss: 0.0417870469391346\n",
      "Epoch : 7, Loss: 0.059667110443115234\n",
      "Epoch : 7, Loss: 0.030443469062447548\n",
      "Epoch : 7, Loss: 0.02306342124938965\n",
      "Epoch : 7, Loss: 0.03821590170264244\n",
      "Epoch : 7, Loss: 0.0682852491736412\n",
      "Epoch : 7, Loss: 0.031353093683719635\n",
      "Epoch : 7, Loss: 0.12036138772964478\n",
      "Epoch : 7, Loss: 0.08404812216758728\n",
      "Epoch : 7, Loss: 0.07479126751422882\n",
      "Epoch : 7, Loss: 0.07491012662649155\n",
      "Epoch : 7, Loss: 0.06320980936288834\n",
      "Epoch : 7, Loss: 0.10688891261816025\n",
      "Epoch : 7, Loss: 0.06159789115190506\n",
      "Epoch : 7, Loss: 0.062258195132017136\n",
      "Epoch : 7, Loss: 0.09120890498161316\n",
      "Epoch : 7, Loss: 0.04665689170360565\n",
      "Epoch : 7, Loss: 0.01779966801404953\n",
      "Epoch : 7, Loss: 0.08131849765777588\n",
      "Epoch : 7, Loss: 0.02574789524078369\n",
      "Epoch : 7, Loss: 0.04926855117082596\n",
      "Epoch : 7, Loss: 0.03380855172872543\n",
      "Epoch : 7, Loss: 0.022524438798427582\n",
      "Epoch : 7, Loss: 0.017542392015457153\n",
      "Epoch : 7, Loss: 0.07018053531646729\n",
      "Epoch : 7, Loss: 0.06380512565374374\n",
      "Epoch : 7, Loss: 0.0461103618144989\n",
      "Epoch : 7, Loss: 0.07876955717802048\n",
      "Epoch : 7, Loss: 0.04948680102825165\n",
      "Epoch : 7, Loss: 0.046254485845565796\n",
      "Epoch : 7, Loss: 0.06282611191272736\n",
      "Epoch : 7, Loss: 0.08147269487380981\n",
      "Epoch : 7, Loss: 0.07333854585886002\n",
      "Epoch : 7, Loss: 0.05431525409221649\n",
      "Epoch : 7, Loss: 0.0966721773147583\n",
      "Epoch : 7, Loss: 0.034479957073926926\n",
      "Epoch : 7, Loss: 0.0384385772049427\n",
      "Epoch : 7, Loss: 0.04411471635103226\n",
      "Epoch : 7, Loss: 0.029678789898753166\n",
      "Epoch : 7, Loss: 0.02252861298620701\n",
      "Epoch : 7, Loss: 0.07044985890388489\n",
      "Epoch : 7, Loss: 0.03379543870687485\n",
      "Epoch : 7, Loss: 0.059265315532684326\n",
      "Epoch : 7, Loss: 0.031802237033843994\n",
      "Epoch : 7, Loss: 0.05635550990700722\n",
      "Epoch : 7, Loss: 0.0808190330862999\n",
      "Epoch : 7, Loss: 0.07041306793689728\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603d17bb5d534dbdbf31d4a360c42f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7381661525369642\n",
      "F1 Score (Micro) = 0.7767288571109374\n",
      "F1 Score (Macro) = 0.7390477930539429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a3c59863eb46b28cb043224350b45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Loss: 0.06110550835728645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8, Loss: 0.05916339159011841\n",
      "Epoch : 8, Loss: 0.01872464269399643\n",
      "Epoch : 8, Loss: 0.031052878126502037\n",
      "Epoch : 8, Loss: 0.04604600742459297\n",
      "Epoch : 8, Loss: 0.07740030437707901\n",
      "Epoch : 8, Loss: 0.07489264756441116\n",
      "Epoch : 8, Loss: 0.09045225381851196\n",
      "Epoch : 8, Loss: 0.04888278990983963\n",
      "Epoch : 8, Loss: 0.09411510080099106\n",
      "Epoch : 8, Loss: 0.053031764924526215\n",
      "Epoch : 8, Loss: 0.0512298159301281\n",
      "Epoch : 8, Loss: 0.02142166532576084\n",
      "Epoch : 8, Loss: 0.016658682376146317\n",
      "Epoch : 8, Loss: 0.0761319175362587\n",
      "Epoch : 8, Loss: 0.027410835027694702\n",
      "Epoch : 8, Loss: 0.045580506324768066\n",
      "Epoch : 8, Loss: 0.016581552103161812\n",
      "Epoch : 8, Loss: 0.060417067259550095\n",
      "Epoch : 8, Loss: 0.01769622601568699\n",
      "Epoch : 8, Loss: 0.10887181758880615\n",
      "Epoch : 8, Loss: 0.054473694413900375\n",
      "Epoch : 8, Loss: 0.020099801942706108\n",
      "Epoch : 8, Loss: 0.04105943441390991\n",
      "Epoch : 8, Loss: 0.05584151670336723\n",
      "Epoch : 8, Loss: 0.025719599798321724\n",
      "Epoch : 8, Loss: 0.04683716967701912\n",
      "Epoch : 8, Loss: 0.029588501900434494\n",
      "Epoch : 8, Loss: 0.04522109031677246\n",
      "Epoch : 8, Loss: 0.02332647703588009\n",
      "Epoch : 8, Loss: 0.05924217402935028\n",
      "Epoch : 8, Loss: 0.05754862353205681\n",
      "Epoch : 8, Loss: 0.051369428634643555\n",
      "Epoch : 8, Loss: 0.07023775577545166\n",
      "Epoch : 8, Loss: 0.04426201432943344\n",
      "Epoch : 8, Loss: 0.043416984379291534\n",
      "Epoch : 8, Loss: 0.03961968049407005\n",
      "Epoch : 8, Loss: 0.1172972172498703\n",
      "Epoch : 8, Loss: 0.020297320559620857\n",
      "Epoch : 8, Loss: 0.04574551433324814\n",
      "Epoch : 8, Loss: 0.023028073832392693\n",
      "Epoch : 8, Loss: 0.03648700565099716\n",
      "Epoch : 8, Loss: 0.07333590090274811\n",
      "Epoch : 8, Loss: 0.09748773276805878\n",
      "Epoch : 8, Loss: 0.04868318885564804\n",
      "Epoch : 8, Loss: 0.027485504746437073\n",
      "Epoch : 8, Loss: 0.0209171362221241\n",
      "Epoch : 8, Loss: 0.025933265686035156\n",
      "Epoch : 8, Loss: 0.08800254017114639\n",
      "Epoch : 8, Loss: 0.030953500419855118\n",
      "Epoch : 8, Loss: 0.04253965616226196\n",
      "Epoch : 8, Loss: 0.07059720903635025\n",
      "Epoch : 8, Loss: 0.024958264082670212\n",
      "Epoch : 8, Loss: 0.08653932809829712\n",
      "Epoch : 8, Loss: 0.09317948669195175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e72fbcfed0d4d8fbb31af7c796c132d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7451334964365494\n",
      "F1 Score (Micro) = 0.7791251384274639\n",
      "F1 Score (Macro) = 0.7445426259279185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c0564de858441cbda0656e32c12494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Loss: 0.09348265081644058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9, Loss: 0.02102944441139698\n",
      "Epoch : 9, Loss: 0.09934689849615097\n",
      "Epoch : 9, Loss: 0.08988483250141144\n",
      "Epoch : 9, Loss: 0.014339401386678219\n",
      "Epoch : 9, Loss: 0.017261546105146408\n",
      "Epoch : 9, Loss: 0.010888266377151012\n",
      "Epoch : 9, Loss: 0.025437919422984123\n",
      "Epoch : 9, Loss: 0.04688269644975662\n",
      "Epoch : 9, Loss: 0.05634310096502304\n",
      "Epoch : 9, Loss: 0.02529107965528965\n",
      "Epoch : 9, Loss: 0.029248183593153954\n",
      "Epoch : 9, Loss: 0.1115405261516571\n",
      "Epoch : 9, Loss: 0.028160057961940765\n",
      "Epoch : 9, Loss: 0.024482445791363716\n",
      "Epoch : 9, Loss: 0.02168283239006996\n",
      "Epoch : 9, Loss: 0.09332415461540222\n",
      "Epoch : 9, Loss: 0.05333608388900757\n",
      "Epoch : 9, Loss: 0.07753019034862518\n",
      "Epoch : 9, Loss: 0.03222288563847542\n",
      "Epoch : 9, Loss: 0.0799209326505661\n",
      "Epoch : 9, Loss: 0.060979217290878296\n",
      "Epoch : 9, Loss: 0.019227121025323868\n",
      "Epoch : 9, Loss: 0.037778306752443314\n",
      "Epoch : 9, Loss: 0.039671141654253006\n",
      "Epoch : 9, Loss: 0.04344687983393669\n",
      "Epoch : 9, Loss: 0.04978656396269798\n",
      "Epoch : 9, Loss: 0.04164402559399605\n",
      "Epoch : 9, Loss: 0.04061505198478699\n",
      "Epoch : 9, Loss: 0.03638676553964615\n",
      "Epoch : 9, Loss: 0.01557483896613121\n",
      "Epoch : 9, Loss: 0.0970982015132904\n",
      "Epoch : 9, Loss: 0.06994184106588364\n",
      "Epoch : 9, Loss: 0.07635565847158432\n",
      "Epoch : 9, Loss: 0.03269072622060776\n",
      "Epoch : 9, Loss: 0.018424632027745247\n",
      "Epoch : 9, Loss: 0.055941224098205566\n",
      "Epoch : 9, Loss: 0.02396041713654995\n",
      "Epoch : 9, Loss: 0.018649080768227577\n",
      "Epoch : 9, Loss: 0.04162222892045975\n",
      "Epoch : 9, Loss: 0.027477869763970375\n",
      "Epoch : 9, Loss: 0.02392132207751274\n",
      "Epoch : 9, Loss: 0.08821777999401093\n",
      "Epoch : 9, Loss: 0.01360742375254631\n",
      "Epoch : 9, Loss: 0.011417522095143795\n",
      "Epoch : 9, Loss: 0.031063169240951538\n",
      "Epoch : 9, Loss: 0.006683848332613707\n",
      "Epoch : 9, Loss: 0.049290262162685394\n",
      "Epoch : 9, Loss: 0.04523278400301933\n",
      "Epoch : 9, Loss: 0.08658911287784576\n",
      "Epoch : 9, Loss: 0.09766539931297302\n",
      "Epoch : 9, Loss: 0.0364665687084198\n",
      "Epoch : 9, Loss: 0.0428142175078392\n",
      "Epoch : 9, Loss: 0.08987130224704742\n",
      "Epoch : 9, Loss: 0.018205080181360245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce0d9ec2a5b4b61b00e80e9a47014d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.753909158600149\n",
      "F1 Score (Micro) = 0.7858128622688381\n",
      "F1 Score (Macro) = 0.754886080443203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65b4e7eb4b445aba052851cce0e5d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Loss: 0.05796576291322708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10, Loss: 0.03182162716984749\n",
      "Epoch : 10, Loss: 0.04772697016596794\n",
      "Epoch : 10, Loss: 0.03509773686528206\n",
      "Epoch : 10, Loss: 0.03778241574764252\n",
      "Epoch : 10, Loss: 0.06675887852907181\n",
      "Epoch : 10, Loss: 0.058763861656188965\n",
      "Epoch : 10, Loss: 0.07671232521533966\n",
      "Epoch : 10, Loss: 0.0603983998298645\n",
      "Epoch : 10, Loss: 0.019680630415678024\n",
      "Epoch : 10, Loss: 0.030941754579544067\n",
      "Epoch : 10, Loss: 0.06007719039916992\n",
      "Epoch : 10, Loss: 0.05910199508070946\n",
      "Epoch : 10, Loss: 0.045865993946790695\n",
      "Epoch : 10, Loss: 0.02029108814895153\n",
      "Epoch : 10, Loss: 0.05671427771449089\n",
      "Epoch : 10, Loss: 0.009416001848876476\n",
      "Epoch : 10, Loss: 0.013869600370526314\n",
      "Epoch : 10, Loss: 0.019315531477332115\n",
      "Epoch : 10, Loss: 0.012850050814449787\n",
      "Epoch : 10, Loss: 0.07631916552782059\n",
      "Epoch : 10, Loss: 0.06285618990659714\n",
      "Epoch : 10, Loss: 0.027903852984309196\n",
      "Epoch : 10, Loss: 0.02094591222703457\n",
      "Epoch : 10, Loss: 0.03741409629583359\n",
      "Epoch : 10, Loss: 0.07273228466510773\n",
      "Epoch : 10, Loss: 0.021600982174277306\n",
      "Epoch : 10, Loss: 0.03019896149635315\n",
      "Epoch : 10, Loss: 0.028865614905953407\n",
      "Epoch : 10, Loss: 0.02955305203795433\n",
      "Epoch : 10, Loss: 0.04262951761484146\n",
      "Epoch : 10, Loss: 0.0436469167470932\n",
      "Epoch : 10, Loss: 0.09236034005880356\n",
      "Epoch : 10, Loss: 0.04062136635184288\n",
      "Epoch : 10, Loss: 0.038909271359443665\n",
      "Epoch : 10, Loss: 0.06411855667829514\n",
      "Epoch : 10, Loss: 0.01868225261569023\n",
      "Epoch : 10, Loss: 0.021797144785523415\n",
      "Epoch : 10, Loss: 0.04908788949251175\n",
      "Epoch : 10, Loss: 0.03443363681435585\n",
      "Epoch : 10, Loss: 0.05716942250728607\n",
      "Epoch : 10, Loss: 0.022395001724362373\n",
      "Epoch : 10, Loss: 0.05615619197487831\n",
      "Epoch : 10, Loss: 0.08148853480815887\n",
      "Epoch : 10, Loss: 0.01426046621054411\n",
      "Epoch : 10, Loss: 0.02388771064579487\n",
      "Epoch : 10, Loss: 0.047169122844934464\n",
      "Epoch : 10, Loss: 0.006108161062002182\n",
      "Epoch : 10, Loss: 0.039403755217790604\n",
      "Epoch : 10, Loss: 0.038765858858823776\n",
      "Epoch : 10, Loss: 0.02102839946746826\n",
      "Epoch : 10, Loss: 0.07445304095745087\n",
      "Epoch : 10, Loss: 0.04521478712558746\n",
      "Epoch : 10, Loss: 0.062318310141563416\n",
      "Epoch : 10, Loss: 0.03995361924171448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7ca2c04dff4f12a899fe8da8d838eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7581640251037124\n",
      "F1 Score (Micro) = 0.7870726613169177\n",
      "F1 Score (Macro) = 0.7618230896792796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539fe06cf4204b96b0e941e0e8211370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Loss: 0.1496146023273468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11, Loss: 0.019067125394940376\n",
      "Epoch : 11, Loss: 0.05332038924098015\n",
      "Epoch : 11, Loss: 0.028101276606321335\n",
      "Epoch : 11, Loss: 0.014246287755668163\n",
      "Epoch : 11, Loss: 0.02887996844947338\n",
      "Epoch : 11, Loss: 0.04759807139635086\n",
      "Epoch : 11, Loss: 0.035088904201984406\n",
      "Epoch : 11, Loss: 0.04502280429005623\n",
      "Epoch : 11, Loss: 0.03364913538098335\n",
      "Epoch : 11, Loss: 0.015653805807232857\n",
      "Epoch : 11, Loss: 0.043282996863126755\n",
      "Epoch : 11, Loss: 0.09374198317527771\n",
      "Epoch : 11, Loss: 0.10050316900014877\n",
      "Epoch : 11, Loss: 0.07983753830194473\n",
      "Epoch : 11, Loss: 0.023277848958969116\n",
      "Epoch : 11, Loss: 0.015879768878221512\n",
      "Epoch : 11, Loss: 0.06530904769897461\n",
      "Epoch : 11, Loss: 0.03163684532046318\n",
      "Epoch : 11, Loss: 0.09177891165018082\n",
      "Epoch : 11, Loss: 0.037663690745830536\n",
      "Epoch : 11, Loss: 0.0215010829269886\n",
      "Epoch : 11, Loss: 0.0641266331076622\n",
      "Epoch : 11, Loss: 0.016895726323127747\n",
      "Epoch : 11, Loss: 0.01928120106458664\n",
      "Epoch : 11, Loss: 0.043364811688661575\n",
      "Epoch : 11, Loss: 0.04196972772479057\n",
      "Epoch : 11, Loss: 0.044333651661872864\n",
      "Epoch : 11, Loss: 0.07033926993608475\n",
      "Epoch : 11, Loss: 0.014186449348926544\n",
      "Epoch : 11, Loss: 0.010274941101670265\n",
      "Epoch : 11, Loss: 0.05992798134684563\n",
      "Epoch : 11, Loss: 0.02430862747132778\n",
      "Epoch : 11, Loss: 0.021232131868600845\n",
      "Epoch : 11, Loss: 0.016373222693800926\n",
      "Epoch : 11, Loss: 0.023914868012070656\n",
      "Epoch : 11, Loss: 0.0206131711602211\n",
      "Epoch : 11, Loss: 0.02596144936978817\n",
      "Epoch : 11, Loss: 0.030445769429206848\n",
      "Epoch : 11, Loss: 0.06645707041025162\n",
      "Epoch : 11, Loss: 0.036566633731126785\n",
      "Epoch : 11, Loss: 0.03667674958705902\n",
      "Epoch : 11, Loss: 0.052645787596702576\n",
      "Epoch : 11, Loss: 0.04149753227829933\n",
      "Epoch : 11, Loss: 0.011379285715520382\n",
      "Epoch : 11, Loss: 0.01167091354727745\n",
      "Epoch : 11, Loss: 0.015500280074775219\n",
      "Epoch : 11, Loss: 0.05740457400679588\n",
      "Epoch : 11, Loss: 0.013388599269092083\n",
      "Epoch : 11, Loss: 0.0653400719165802\n",
      "Epoch : 11, Loss: 0.021130528301000595\n",
      "Epoch : 11, Loss: 0.04629657045006752\n",
      "Epoch : 11, Loss: 0.015154589898884296\n",
      "Epoch : 11, Loss: 0.026015963405370712\n",
      "Epoch : 11, Loss: 0.014877434819936752\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf1721cdf10412893f21f3a84390499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7612488033187959\n",
      "F1 Score (Micro) = 0.787953524060068\n",
      "F1 Score (Macro) = 0.7636870639701776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b84b9005327479ead9ca14a8b3c9d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Loss: 0.043246135115623474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12, Loss: 0.06533662974834442\n",
      "Epoch : 12, Loss: 0.01915767230093479\n",
      "Epoch : 12, Loss: 0.034539517015218735\n",
      "Epoch : 12, Loss: 0.03640839830040932\n",
      "Epoch : 12, Loss: 0.008425967767834663\n",
      "Epoch : 12, Loss: 0.028780382126569748\n",
      "Epoch : 12, Loss: 0.029985228553414345\n",
      "Epoch : 12, Loss: 0.03937448188662529\n",
      "Epoch : 12, Loss: 0.018793167546391487\n",
      "Epoch : 12, Loss: 0.06532581150531769\n",
      "Epoch : 12, Loss: 0.048285387456417084\n",
      "Epoch : 12, Loss: 0.020214572548866272\n",
      "Epoch : 12, Loss: 0.06306330859661102\n",
      "Epoch : 12, Loss: 0.03717793524265289\n",
      "Epoch : 12, Loss: 0.02372984029352665\n",
      "Epoch : 12, Loss: 0.017878899350762367\n",
      "Epoch : 12, Loss: 0.009331703186035156\n",
      "Epoch : 12, Loss: 0.09665507078170776\n",
      "Epoch : 12, Loss: 0.0372711606323719\n",
      "Epoch : 12, Loss: 0.020097950473427773\n",
      "Epoch : 12, Loss: 0.06770926713943481\n",
      "Epoch : 12, Loss: 0.018318258225917816\n",
      "Epoch : 12, Loss: 0.01509969960898161\n",
      "Epoch : 12, Loss: 0.08385120332241058\n",
      "Epoch : 12, Loss: 0.07492155581712723\n",
      "Epoch : 12, Loss: 0.024761492386460304\n",
      "Epoch : 12, Loss: 0.04551120847463608\n",
      "Epoch : 12, Loss: 0.021650299429893494\n",
      "Epoch : 12, Loss: 0.06587009131908417\n",
      "Epoch : 12, Loss: 0.04809277877211571\n",
      "Epoch : 12, Loss: 0.10964857041835785\n",
      "Epoch : 12, Loss: 0.008572310209274292\n",
      "Epoch : 12, Loss: 0.014141511172056198\n",
      "Epoch : 12, Loss: 0.039816342294216156\n",
      "Epoch : 12, Loss: 0.06420892477035522\n",
      "Epoch : 12, Loss: 0.06783205270767212\n",
      "Epoch : 12, Loss: 0.013609140180051327\n",
      "Epoch : 12, Loss: 0.056852590292692184\n",
      "Epoch : 12, Loss: 0.04972778633236885\n",
      "Epoch : 12, Loss: 0.04508308321237564\n",
      "Epoch : 12, Loss: 0.012942786328494549\n",
      "Epoch : 12, Loss: 0.01771460846066475\n",
      "Epoch : 12, Loss: 0.015476896427571774\n",
      "Epoch : 12, Loss: 0.05995392054319382\n",
      "Epoch : 12, Loss: 0.009982690215110779\n",
      "Epoch : 12, Loss: 0.04196866974234581\n",
      "Epoch : 12, Loss: 0.04230909422039986\n",
      "Epoch : 12, Loss: 0.024723494425415993\n",
      "Epoch : 12, Loss: 0.051662545651197433\n",
      "Epoch : 12, Loss: 0.03560524806380272\n",
      "Epoch : 12, Loss: 0.01092788577079773\n",
      "Epoch : 12, Loss: 0.029201796278357506\n",
      "Epoch : 12, Loss: 0.01937514916062355\n",
      "Epoch : 12, Loss: 0.011780515313148499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55ac12e84a14a5ea87499ed93b17230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7660887139665993\n",
      "F1 Score (Micro) = 0.7912867827701043\n",
      "F1 Score (Macro) = 0.767059411196935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72648c282bc74c759b7bf00251ce0696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Loss: 0.04305858910083771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13, Loss: 0.009563367813825607\n",
      "Epoch : 13, Loss: 0.02137107402086258\n",
      "Epoch : 13, Loss: 0.06546147912740707\n",
      "Epoch : 13, Loss: 0.02855057455599308\n",
      "Epoch : 13, Loss: 0.06901013851165771\n",
      "Epoch : 13, Loss: 0.0192361269146204\n",
      "Epoch : 13, Loss: 0.022052353248000145\n",
      "Epoch : 13, Loss: 0.049351442605257034\n",
      "Epoch : 13, Loss: 0.018885314464569092\n",
      "Epoch : 13, Loss: 0.07712049037218094\n",
      "Epoch : 13, Loss: 0.026421794667840004\n",
      "Epoch : 13, Loss: 0.060297414660453796\n",
      "Epoch : 13, Loss: 0.009659710340201855\n",
      "Epoch : 13, Loss: 0.042664188891649246\n",
      "Epoch : 13, Loss: 0.011068922467529774\n",
      "Epoch : 13, Loss: 0.05581307411193848\n",
      "Epoch : 13, Loss: 0.02247941493988037\n",
      "Epoch : 13, Loss: 0.030432075262069702\n",
      "Epoch : 13, Loss: 0.010285302065312862\n",
      "Epoch : 13, Loss: 0.026130344718694687\n",
      "Epoch : 13, Loss: 0.0772210881114006\n",
      "Epoch : 13, Loss: 0.01923268847167492\n",
      "Epoch : 13, Loss: 0.029247596859931946\n",
      "Epoch : 13, Loss: 0.06192100793123245\n",
      "Epoch : 13, Loss: 0.01548527181148529\n",
      "Epoch : 13, Loss: 0.030483877286314964\n",
      "Epoch : 13, Loss: 0.08847085386514664\n",
      "Epoch : 13, Loss: 0.05186855047941208\n",
      "Epoch : 13, Loss: 0.012825589627027512\n",
      "Epoch : 13, Loss: 0.05632637441158295\n",
      "Epoch : 13, Loss: 0.05573831498622894\n",
      "Epoch : 13, Loss: 0.006990035995841026\n",
      "Epoch : 13, Loss: 0.04632715880870819\n",
      "Epoch : 13, Loss: 0.025681069120764732\n",
      "Epoch : 13, Loss: 0.020327286794781685\n",
      "Epoch : 13, Loss: 0.03636518865823746\n",
      "Epoch : 13, Loss: 0.00899512693285942\n",
      "Epoch : 13, Loss: 0.007092015352100134\n",
      "Epoch : 13, Loss: 0.015257518738508224\n",
      "Epoch : 13, Loss: 0.029205869883298874\n",
      "Epoch : 13, Loss: 0.03277266025543213\n",
      "Epoch : 13, Loss: 0.0418018102645874\n",
      "Epoch : 13, Loss: 0.02959972433745861\n",
      "Epoch : 13, Loss: 0.03873227909207344\n",
      "Epoch : 13, Loss: 0.06719189882278442\n",
      "Epoch : 13, Loss: 0.05727214738726616\n",
      "Epoch : 13, Loss: 0.020081350579857826\n",
      "Epoch : 13, Loss: 0.02751530334353447\n",
      "Epoch : 13, Loss: 0.03090163692831993\n",
      "Epoch : 13, Loss: 0.03905550390481949\n",
      "Epoch : 13, Loss: 0.04655223712325096\n",
      "Epoch : 13, Loss: 0.03147226199507713\n",
      "Epoch : 13, Loss: 0.022805461660027504\n",
      "Epoch : 13, Loss: 0.011126667261123657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8712682657924836a67406e4c07b9da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7641208382087012\n",
      "F1 Score (Micro) = 0.7896388896470781\n",
      "F1 Score (Macro) = 0.7672637611508368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350ffc77f602417490fd6a9acf01af97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14, Loss: 0.09417587518692017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14, Loss: 0.056044720113277435\n",
      "Epoch : 14, Loss: 0.007491953205317259\n",
      "Epoch : 14, Loss: 0.07023446261882782\n",
      "Epoch : 14, Loss: 0.06030380725860596\n",
      "Epoch : 14, Loss: 0.005562624428421259\n",
      "Epoch : 14, Loss: 0.035554345697164536\n",
      "Epoch : 14, Loss: 0.0054993657395243645\n",
      "Epoch : 14, Loss: 0.04529701545834541\n",
      "Epoch : 14, Loss: 0.03323620557785034\n",
      "Epoch : 14, Loss: 0.037972062826156616\n",
      "Epoch : 14, Loss: 0.009384747594594955\n",
      "Epoch : 14, Loss: 0.047189779579639435\n",
      "Epoch : 14, Loss: 0.009544441476464272\n",
      "Epoch : 14, Loss: 0.008971288800239563\n",
      "Epoch : 14, Loss: 0.06516800075769424\n",
      "Epoch : 14, Loss: 0.02754795178771019\n",
      "Epoch : 14, Loss: 0.04987059161067009\n",
      "Epoch : 14, Loss: 0.05425193905830383\n",
      "Epoch : 14, Loss: 0.009518779814243317\n",
      "Epoch : 14, Loss: 0.007061958312988281\n",
      "Epoch : 14, Loss: 0.05644109845161438\n",
      "Epoch : 14, Loss: 0.06936897337436676\n",
      "Epoch : 14, Loss: 0.07134420424699783\n",
      "Epoch : 14, Loss: 0.00600821478292346\n",
      "Epoch : 14, Loss: 0.06722406297922134\n",
      "Epoch : 14, Loss: 0.04730422422289848\n",
      "Epoch : 14, Loss: 0.025850877165794373\n",
      "Epoch : 14, Loss: 0.016112230718135834\n",
      "Epoch : 14, Loss: 0.030899303033947945\n",
      "Epoch : 14, Loss: 0.012646384537220001\n",
      "Epoch : 14, Loss: 0.07069385051727295\n",
      "Epoch : 14, Loss: 0.034291382879018784\n",
      "Epoch : 14, Loss: 0.011911705136299133\n",
      "Epoch : 14, Loss: 0.029659241437911987\n",
      "Epoch : 14, Loss: 0.04674656316637993\n",
      "Epoch : 14, Loss: 0.008004019036889076\n",
      "Epoch : 14, Loss: 0.02448766492307186\n",
      "Epoch : 14, Loss: 0.02998102270066738\n",
      "Epoch : 14, Loss: 0.017939740791916847\n",
      "Epoch : 14, Loss: 0.013502119109034538\n",
      "Epoch : 14, Loss: 0.03692154586315155\n",
      "Epoch : 14, Loss: 0.009325871244072914\n",
      "Epoch : 14, Loss: 0.022345105186104774\n",
      "Epoch : 14, Loss: 0.011852296069264412\n",
      "Epoch : 14, Loss: 0.021591942757368088\n",
      "Epoch : 14, Loss: 0.011080913245677948\n",
      "Epoch : 14, Loss: 0.012424680404365063\n",
      "Epoch : 14, Loss: 0.01199826318770647\n",
      "Epoch : 14, Loss: 0.009299295023083687\n",
      "Epoch : 14, Loss: 0.07412043958902359\n",
      "Epoch : 14, Loss: 0.015639053657650948\n",
      "Epoch : 14, Loss: 0.01142789889127016\n",
      "Epoch : 14, Loss: 0.02624758705496788\n",
      "Epoch : 14, Loss: 0.07594089210033417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db5321cae9a46a2a06baffda3ad57f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7626848207637485\n",
      "F1 Score (Micro) = 0.7875630710486841\n",
      "F1 Score (Macro) = 0.7662570662832615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8476daf766574238a42043d128444e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15, Loss: 0.014771074056625366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15, Loss: 0.04750944301486015\n",
      "Epoch : 15, Loss: 0.011221314780414104\n",
      "Epoch : 15, Loss: 0.015812406316399574\n",
      "Epoch : 15, Loss: 0.07406593859195709\n",
      "Epoch : 15, Loss: 0.0479063019156456\n",
      "Epoch : 15, Loss: 0.0171759482473135\n",
      "Epoch : 15, Loss: 0.013892002403736115\n",
      "Epoch : 15, Loss: 0.018351558595895767\n",
      "Epoch : 15, Loss: 0.047099560499191284\n",
      "Epoch : 15, Loss: 0.009411361999809742\n",
      "Epoch : 15, Loss: 0.03764636069536209\n",
      "Epoch : 15, Loss: 0.008883865550160408\n",
      "Epoch : 15, Loss: 0.00832811463624239\n",
      "Epoch : 15, Loss: 0.01379362866282463\n",
      "Epoch : 15, Loss: 0.011089583858847618\n",
      "Epoch : 15, Loss: 0.06709916889667511\n",
      "Epoch : 15, Loss: 0.051169395446777344\n",
      "Epoch : 15, Loss: 0.06871108710765839\n",
      "Epoch : 15, Loss: 0.05256979167461395\n",
      "Epoch : 15, Loss: 0.011110794730484486\n",
      "Epoch : 15, Loss: 0.0835326761007309\n",
      "Epoch : 15, Loss: 0.04056454822421074\n",
      "Epoch : 15, Loss: 0.010972033254802227\n",
      "Epoch : 15, Loss: 0.027575384825468063\n",
      "Epoch : 15, Loss: 0.1036536917090416\n",
      "Epoch : 15, Loss: 0.056231219321489334\n",
      "Epoch : 15, Loss: 0.026097770780324936\n",
      "Epoch : 15, Loss: 0.0259981919080019\n",
      "Epoch : 15, Loss: 0.023050861433148384\n",
      "Epoch : 15, Loss: 0.04248346760869026\n",
      "Epoch : 15, Loss: 0.012115481309592724\n",
      "Epoch : 15, Loss: 0.015373198315501213\n",
      "Epoch : 15, Loss: 0.08677652478218079\n",
      "Epoch : 15, Loss: 0.06076836213469505\n",
      "Epoch : 15, Loss: 0.019702797755599022\n",
      "Epoch : 15, Loss: 0.06781692057847977\n",
      "Epoch : 15, Loss: 0.0244522076100111\n",
      "Epoch : 15, Loss: 0.012315940111875534\n",
      "Epoch : 15, Loss: 0.023137276992201805\n",
      "Epoch : 15, Loss: 0.021926024928689003\n",
      "Epoch : 15, Loss: 0.02944016270339489\n",
      "Epoch : 15, Loss: 0.05493546649813652\n",
      "Epoch : 15, Loss: 0.031048450618982315\n",
      "Epoch : 15, Loss: 0.01757357269525528\n",
      "Epoch : 15, Loss: 0.0343770869076252\n",
      "Epoch : 15, Loss: 0.03323427587747574\n",
      "Epoch : 15, Loss: 0.008676745928823948\n",
      "Epoch : 15, Loss: 0.02617380954325199\n",
      "Epoch : 15, Loss: 0.10629863291978836\n",
      "Epoch : 15, Loss: 0.0346769280731678\n",
      "Epoch : 15, Loss: 0.03149039298295975\n",
      "Epoch : 15, Loss: 0.07702960819005966\n",
      "Epoch : 15, Loss: 0.007698034401983023\n",
      "Epoch : 15, Loss: 0.0358709990978241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b34e07d708146ffb7aa653e91a7ed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7701308371449845\n",
      "F1 Score (Micro) = 0.792242713963658\n",
      "F1 Score (Macro) = 0.7725190635841064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc5aea2eac34321941a061120383295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16, Loss: 0.06728056818246841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16, Loss: 0.02753746509552002\n",
      "Epoch : 16, Loss: 0.03913513571023941\n",
      "Epoch : 16, Loss: 0.019381845369935036\n",
      "Epoch : 16, Loss: 0.021944383159279823\n",
      "Epoch : 16, Loss: 0.016322065144777298\n",
      "Epoch : 16, Loss: 0.035885848104953766\n",
      "Epoch : 16, Loss: 0.007169563788920641\n",
      "Epoch : 16, Loss: 0.028592418879270554\n",
      "Epoch : 16, Loss: 0.1119779497385025\n",
      "Epoch : 16, Loss: 0.008977502584457397\n",
      "Epoch : 16, Loss: 0.010150616057217121\n",
      "Epoch : 16, Loss: 0.0965854823589325\n",
      "Epoch : 16, Loss: 0.0680793896317482\n",
      "Epoch : 16, Loss: 0.03911036252975464\n",
      "Epoch : 16, Loss: 0.06563226878643036\n",
      "Epoch : 16, Loss: 0.014680741354823112\n",
      "Epoch : 16, Loss: 0.04575183987617493\n",
      "Epoch : 16, Loss: 0.02047031931579113\n",
      "Epoch : 16, Loss: 0.01862233877182007\n",
      "Epoch : 16, Loss: 0.007362499367445707\n",
      "Epoch : 16, Loss: 0.028658954426646233\n",
      "Epoch : 16, Loss: 0.058442696928977966\n",
      "Epoch : 16, Loss: 0.026312535628676414\n",
      "Epoch : 16, Loss: 0.06247231364250183\n",
      "Epoch : 16, Loss: 0.04954229295253754\n",
      "Epoch : 16, Loss: 0.01526288315653801\n",
      "Epoch : 16, Loss: 0.05114463344216347\n",
      "Epoch : 16, Loss: 0.008782543241977692\n",
      "Epoch : 16, Loss: 0.01873580738902092\n",
      "Epoch : 16, Loss: 0.05830710753798485\n",
      "Epoch : 16, Loss: 0.057365234941244125\n",
      "Epoch : 16, Loss: 0.009979289956390858\n",
      "Epoch : 16, Loss: 0.04960823059082031\n",
      "Epoch : 16, Loss: 0.06904922425746918\n",
      "Epoch : 16, Loss: 0.023396680131554604\n",
      "Epoch : 16, Loss: 0.022437065839767456\n",
      "Epoch : 16, Loss: 0.03435710445046425\n",
      "Epoch : 16, Loss: 0.010678417980670929\n",
      "Epoch : 16, Loss: 0.02104349620640278\n",
      "Epoch : 16, Loss: 0.015164254233241081\n",
      "Epoch : 16, Loss: 0.03638094663619995\n",
      "Epoch : 16, Loss: 0.00789199210703373\n",
      "Epoch : 16, Loss: 0.02874414063990116\n",
      "Epoch : 16, Loss: 0.007778574246913195\n",
      "Epoch : 16, Loss: 0.015704894438385963\n",
      "Epoch : 16, Loss: 0.02820282243192196\n",
      "Epoch : 16, Loss: 0.006203374359756708\n",
      "Epoch : 16, Loss: 0.011188055388629436\n",
      "Epoch : 16, Loss: 0.06536714732646942\n",
      "Epoch : 16, Loss: 0.030297812074422836\n",
      "Epoch : 16, Loss: 0.0094199413433671\n",
      "Epoch : 16, Loss: 0.03460702300071716\n",
      "Epoch : 16, Loss: 0.04880201444029808\n",
      "Epoch : 16, Loss: 0.005989660043269396\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b49b8d3c3c1448b90306db2db3d2e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.77007765131369\n",
      "F1 Score (Micro) = 0.7918814782655886\n",
      "F1 Score (Macro) = 0.7713324501863146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec9d3872ad54e649a95561ecaed864d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17, Loss: 0.06311362981796265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17, Loss: 0.008715939708054066\n",
      "Epoch : 17, Loss: 0.049048636108636856\n",
      "Epoch : 17, Loss: 0.058733850717544556\n",
      "Epoch : 17, Loss: 0.02264351211488247\n",
      "Epoch : 17, Loss: 0.03717943653464317\n",
      "Epoch : 17, Loss: 0.0193589199334383\n",
      "Epoch : 17, Loss: 0.03486867994070053\n",
      "Epoch : 17, Loss: 0.04340147599577904\n",
      "Epoch : 17, Loss: 0.052635401487350464\n",
      "Epoch : 17, Loss: 0.013702341355383396\n",
      "Epoch : 17, Loss: 0.04264449700713158\n",
      "Epoch : 17, Loss: 0.0047691743820905685\n",
      "Epoch : 17, Loss: 0.08212699741125107\n",
      "Epoch : 17, Loss: 0.014323782175779343\n",
      "Epoch : 17, Loss: 0.043948885053396225\n",
      "Epoch : 17, Loss: 0.021592775359749794\n",
      "Epoch : 17, Loss: 0.010396648198366165\n",
      "Epoch : 17, Loss: 0.08282750099897385\n",
      "Epoch : 17, Loss: 0.10769802331924438\n",
      "Epoch : 17, Loss: 0.026541566476225853\n",
      "Epoch : 17, Loss: 0.012025808915495872\n",
      "Epoch : 17, Loss: 0.010848104022443295\n",
      "Epoch : 17, Loss: 0.017449067905545235\n",
      "Epoch : 17, Loss: 0.006214098539203405\n",
      "Epoch : 17, Loss: 0.019593775272369385\n",
      "Epoch : 17, Loss: 0.03125346451997757\n",
      "Epoch : 17, Loss: 0.013406561687588692\n",
      "Epoch : 17, Loss: 0.08326195925474167\n",
      "Epoch : 17, Loss: 0.06417398154735565\n",
      "Epoch : 17, Loss: 0.07268979400396347\n",
      "Epoch : 17, Loss: 0.018333042040467262\n",
      "Epoch : 17, Loss: 0.006975490599870682\n",
      "Epoch : 17, Loss: 0.06389543414115906\n",
      "Epoch : 17, Loss: 0.020565271377563477\n",
      "Epoch : 17, Loss: 0.01394056249409914\n",
      "Epoch : 17, Loss: 0.04338568449020386\n",
      "Epoch : 17, Loss: 0.015087306499481201\n",
      "Epoch : 17, Loss: 0.1102316826581955\n",
      "Epoch : 17, Loss: 0.014290070161223412\n",
      "Epoch : 17, Loss: 0.08493649959564209\n",
      "Epoch : 17, Loss: 0.014899828471243382\n",
      "Epoch : 17, Loss: 0.013665814884006977\n",
      "Epoch : 17, Loss: 0.012941764667630196\n",
      "Epoch : 17, Loss: 0.00830301083624363\n",
      "Epoch : 17, Loss: 0.0036700440105050802\n",
      "Epoch : 17, Loss: 0.0484834760427475\n",
      "Epoch : 17, Loss: 0.06742741167545319\n",
      "Epoch : 17, Loss: 0.050873856991529465\n",
      "Epoch : 17, Loss: 0.020650170743465424\n",
      "Epoch : 17, Loss: 0.03708362951874733\n",
      "Epoch : 17, Loss: 0.026932746171951294\n",
      "Epoch : 17, Loss: 0.029295867308974266\n",
      "Epoch : 17, Loss: 0.005235981196165085\n",
      "Epoch : 17, Loss: 0.01567045785486698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78375503f5974032880817451aaa05bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7724710137219445\n",
      "F1 Score (Micro) = 0.7922373193309155\n",
      "F1 Score (Macro) = 0.7708788082197953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00313ce078a64e99bc452d4fcf1c7a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18, Loss: 0.022004568949341774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18, Loss: 0.006482935510575771\n",
      "Epoch : 18, Loss: 0.058421775698661804\n",
      "Epoch : 18, Loss: 0.02016504667699337\n",
      "Epoch : 18, Loss: 0.019245171919465065\n",
      "Epoch : 18, Loss: 0.008025765419006348\n",
      "Epoch : 18, Loss: 0.058058567345142365\n",
      "Epoch : 18, Loss: 0.004253846127539873\n",
      "Epoch : 18, Loss: 0.07488051056861877\n",
      "Epoch : 18, Loss: 0.03796527907252312\n",
      "Epoch : 18, Loss: 0.00674297334626317\n",
      "Epoch : 18, Loss: 0.01833447813987732\n",
      "Epoch : 18, Loss: 0.04853806272149086\n",
      "Epoch : 18, Loss: 0.017307765781879425\n",
      "Epoch : 18, Loss: 0.047112882137298584\n",
      "Epoch : 18, Loss: 0.036338381469249725\n",
      "Epoch : 18, Loss: 0.01729266531765461\n",
      "Epoch : 18, Loss: 0.022684326395392418\n",
      "Epoch : 18, Loss: 0.05279519036412239\n",
      "Epoch : 18, Loss: 0.01627092994749546\n",
      "Epoch : 18, Loss: 0.03979542851448059\n",
      "Epoch : 18, Loss: 0.0139381755143404\n",
      "Epoch : 18, Loss: 0.06137071177363396\n",
      "Epoch : 18, Loss: 0.04276400804519653\n",
      "Epoch : 18, Loss: 0.046730298548936844\n",
      "Epoch : 18, Loss: 0.009821632876992226\n",
      "Epoch : 18, Loss: 0.017886236310005188\n",
      "Epoch : 18, Loss: 0.007866663858294487\n",
      "Epoch : 18, Loss: 0.02385699562728405\n",
      "Epoch : 18, Loss: 0.04112108051776886\n",
      "Epoch : 18, Loss: 0.06387300044298172\n",
      "Epoch : 18, Loss: 0.023444585502147675\n",
      "Epoch : 18, Loss: 0.01240415871143341\n",
      "Epoch : 18, Loss: 0.05571591481566429\n",
      "Epoch : 18, Loss: 0.0075595625676214695\n",
      "Epoch : 18, Loss: 0.010984490625560284\n",
      "Epoch : 18, Loss: 0.07824672013521194\n",
      "Epoch : 18, Loss: 0.045118626207113266\n",
      "Epoch : 18, Loss: 0.01002887450158596\n",
      "Epoch : 18, Loss: 0.02439478412270546\n",
      "Epoch : 18, Loss: 0.019743870943784714\n",
      "Epoch : 18, Loss: 0.022857848554849625\n",
      "Epoch : 18, Loss: 0.009369688108563423\n",
      "Epoch : 18, Loss: 0.006751097273081541\n",
      "Epoch : 18, Loss: 0.015257730148732662\n",
      "Epoch : 18, Loss: 0.011607113294303417\n",
      "Epoch : 18, Loss: 0.006051334086805582\n",
      "Epoch : 18, Loss: 0.03069274127483368\n",
      "Epoch : 18, Loss: 0.004234731197357178\n",
      "Epoch : 18, Loss: 0.011990793980658054\n",
      "Epoch : 18, Loss: 0.04229278489947319\n",
      "Epoch : 18, Loss: 0.004320039413869381\n",
      "Epoch : 18, Loss: 0.05524866282939911\n",
      "Epoch : 18, Loss: 0.08439302444458008\n",
      "Epoch : 18, Loss: 0.08763366937637329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6d2bee5827422e956aa1256d51ac39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.77066269545793\n",
      "F1 Score (Micro) = 0.7910568666630665\n",
      "F1 Score (Macro) = 0.7706077872996177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6ef88b4ff24ad393629736e13ae1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, Loss: 0.04706890508532524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19, Loss: 0.027006974443793297\n",
      "Epoch : 19, Loss: 0.020608633756637573\n",
      "Epoch : 19, Loss: 0.011650440283119678\n",
      "Epoch : 19, Loss: 0.042140066623687744\n",
      "Epoch : 19, Loss: 0.03221800923347473\n",
      "Epoch : 19, Loss: 0.011594324372708797\n",
      "Epoch : 19, Loss: 0.009919267147779465\n",
      "Epoch : 19, Loss: 0.0813227966427803\n",
      "Epoch : 19, Loss: 0.05157792195677757\n",
      "Epoch : 19, Loss: 0.008869362063705921\n",
      "Epoch : 19, Loss: 0.00852241925895214\n",
      "Epoch : 19, Loss: 0.05480451136827469\n",
      "Epoch : 19, Loss: 0.036865234375\n",
      "Epoch : 19, Loss: 0.044087380170822144\n",
      "Epoch : 19, Loss: 0.06353308260440826\n",
      "Epoch : 19, Loss: 0.053181152790784836\n",
      "Epoch : 19, Loss: 0.009801015257835388\n",
      "Epoch : 19, Loss: 0.03739366680383682\n",
      "Epoch : 19, Loss: 0.028332170099020004\n",
      "Epoch : 19, Loss: 0.03775127977132797\n",
      "Epoch : 19, Loss: 0.018086601048707962\n",
      "Epoch : 19, Loss: 0.005003987345844507\n",
      "Epoch : 19, Loss: 0.02373078465461731\n",
      "Epoch : 19, Loss: 0.005279166623950005\n",
      "Epoch : 19, Loss: 0.031695663928985596\n",
      "Epoch : 19, Loss: 0.05124521255493164\n",
      "Epoch : 19, Loss: 0.02609712816774845\n",
      "Epoch : 19, Loss: 0.04095415771007538\n",
      "Epoch : 19, Loss: 0.036813944578170776\n",
      "Epoch : 19, Loss: 0.026918655261397362\n",
      "Epoch : 19, Loss: 0.006987878121435642\n",
      "Epoch : 19, Loss: 0.04062579944729805\n",
      "Epoch : 19, Loss: 0.0067611271515488625\n",
      "Epoch : 19, Loss: 0.006112999748438597\n",
      "Epoch : 19, Loss: 0.07185019552707672\n",
      "Epoch : 19, Loss: 0.013715341687202454\n",
      "Epoch : 19, Loss: 0.004689541179686785\n",
      "Epoch : 19, Loss: 0.016690073534846306\n",
      "Epoch : 19, Loss: 0.0943383201956749\n",
      "Epoch : 19, Loss: 0.04927849769592285\n",
      "Epoch : 19, Loss: 0.023972922936081886\n",
      "Epoch : 19, Loss: 0.01345414761453867\n",
      "Epoch : 19, Loss: 0.04948365315794945\n",
      "Epoch : 19, Loss: 0.007928255945444107\n",
      "Epoch : 19, Loss: 0.022904694080352783\n",
      "Epoch : 19, Loss: 0.03647449612617493\n",
      "Epoch : 19, Loss: 0.05397002026438713\n",
      "Epoch : 19, Loss: 0.07533426582813263\n",
      "Epoch : 19, Loss: 0.04071689397096634\n",
      "Epoch : 19, Loss: 0.059843651950359344\n",
      "Epoch : 19, Loss: 0.008895481936633587\n",
      "Epoch : 19, Loss: 0.029411401599645615\n",
      "Epoch : 19, Loss: 0.01868349500000477\n",
      "Epoch : 19, Loss: 0.0565146803855896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae203b86e6784c4abf60a67d7c9fe669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7724178278906499\n",
      "F1 Score (Micro) = 0.7922014622258327\n",
      "F1 Score (Macro) = 0.7689329700420756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abe450563b445e3983edbace4d7fdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, Loss: 0.02590835653245449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, Loss: 0.007442794740200043\n",
      "Epoch : 20, Loss: 0.009082143194973469\n",
      "Epoch : 20, Loss: 0.0919538214802742\n",
      "Epoch : 20, Loss: 0.046349067240953445\n",
      "Epoch : 20, Loss: 0.007415243424475193\n",
      "Epoch : 20, Loss: 0.018225282430648804\n",
      "Epoch : 20, Loss: 0.017983360216021538\n",
      "Epoch : 20, Loss: 0.006196422036737204\n",
      "Epoch : 20, Loss: 0.023389101028442383\n",
      "Epoch : 20, Loss: 0.00572170689702034\n",
      "Epoch : 20, Loss: 0.004445668309926987\n",
      "Epoch : 20, Loss: 0.026117097586393356\n",
      "Epoch : 20, Loss: 0.04301447048783302\n",
      "Epoch : 20, Loss: 0.05496308207511902\n",
      "Epoch : 20, Loss: 0.05381910502910614\n",
      "Epoch : 20, Loss: 0.04094290733337402\n",
      "Epoch : 20, Loss: 0.0065098232589662075\n",
      "Epoch : 20, Loss: 0.02165764570236206\n",
      "Epoch : 20, Loss: 0.014708487316966057\n",
      "Epoch : 20, Loss: 0.012142425402998924\n",
      "Epoch : 20, Loss: 0.046218693256378174\n",
      "Epoch : 20, Loss: 0.016536895185709\n",
      "Epoch : 20, Loss: 0.010393597185611725\n",
      "Epoch : 20, Loss: 0.007856421172618866\n",
      "Epoch : 20, Loss: 0.011905880644917488\n",
      "Epoch : 20, Loss: 0.04193951562047005\n",
      "Epoch : 20, Loss: 0.04442897439002991\n",
      "Epoch : 20, Loss: 0.05452656000852585\n",
      "Epoch : 20, Loss: 0.0230515506118536\n",
      "Epoch : 20, Loss: 0.03268244490027428\n",
      "Epoch : 20, Loss: 0.007252187933772802\n",
      "Epoch : 20, Loss: 0.020197326317429543\n",
      "Epoch : 20, Loss: 0.006140768062323332\n",
      "Epoch : 20, Loss: 0.024241378530859947\n",
      "Epoch : 20, Loss: 0.0717095211148262\n",
      "Epoch : 20, Loss: 0.027196118608117104\n",
      "Epoch : 20, Loss: 0.022091422230005264\n",
      "Epoch : 20, Loss: 0.009420059621334076\n",
      "Epoch : 20, Loss: 0.00752408429980278\n",
      "Epoch : 20, Loss: 0.028469230979681015\n",
      "Epoch : 20, Loss: 0.023923495784401894\n",
      "Epoch : 20, Loss: 0.03598091006278992\n",
      "Epoch : 20, Loss: 0.014055307023227215\n",
      "Epoch : 20, Loss: 0.0203719399869442\n",
      "Epoch : 20, Loss: 0.005294647067785263\n",
      "Epoch : 20, Loss: 0.04824370890855789\n",
      "Epoch : 20, Loss: 0.006820955313742161\n",
      "Epoch : 20, Loss: 0.008968832902610302\n",
      "Epoch : 20, Loss: 0.03874142840504646\n",
      "Epoch : 20, Loss: 0.004232127219438553\n",
      "Epoch : 20, Loss: 0.015453962609171867\n",
      "Epoch : 20, Loss: 0.02189050056040287\n",
      "Epoch : 20, Loss: 0.0031904196366667747\n",
      "Epoch : 20, Loss: 0.006867922842502594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02411b63078434f9e0d71eef4e67dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7717264120838209\n",
      "F1 Score (Micro) = 0.7903500013492728\n",
      "F1 Score (Macro) = 0.7705462699753494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1189f3f86e0840a6942cf640e6591628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21, Loss: 0.01081903837621212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21, Loss: 0.06380029022693634\n",
      "Epoch : 21, Loss: 0.04832157492637634\n",
      "Epoch : 21, Loss: 0.010803595185279846\n",
      "Epoch : 21, Loss: 0.0032757516019046307\n",
      "Epoch : 21, Loss: 0.007061680778861046\n",
      "Epoch : 21, Loss: 0.016756756231188774\n",
      "Epoch : 21, Loss: 0.047199834138154984\n",
      "Epoch : 21, Loss: 0.012568448670208454\n",
      "Epoch : 21, Loss: 0.03022177144885063\n",
      "Epoch : 21, Loss: 0.04839985445141792\n",
      "Epoch : 21, Loss: 0.007864226587116718\n",
      "Epoch : 21, Loss: 0.008572563529014587\n",
      "Epoch : 21, Loss: 0.01729528047144413\n",
      "Epoch : 21, Loss: 0.023931538686156273\n",
      "Epoch : 21, Loss: 0.06519333273172379\n",
      "Epoch : 21, Loss: 0.012670486234128475\n",
      "Epoch : 21, Loss: 0.025028137490153313\n",
      "Epoch : 21, Loss: 0.01622973568737507\n",
      "Epoch : 21, Loss: 0.05252900719642639\n",
      "Epoch : 21, Loss: 0.004363825544714928\n",
      "Epoch : 21, Loss: 0.03724713623523712\n",
      "Epoch : 21, Loss: 0.009689396247267723\n",
      "Epoch : 21, Loss: 0.0038113025948405266\n",
      "Epoch : 21, Loss: 0.006031122524291277\n",
      "Epoch : 21, Loss: 0.010834237560629845\n",
      "Epoch : 21, Loss: 0.003949830774217844\n",
      "Epoch : 21, Loss: 0.008159413933753967\n",
      "Epoch : 21, Loss: 0.008677108213305473\n",
      "Epoch : 21, Loss: 0.0038744236808270216\n",
      "Epoch : 21, Loss: 0.0025737378746271133\n",
      "Epoch : 21, Loss: 0.023189300671219826\n",
      "Epoch : 21, Loss: 0.06455621868371964\n",
      "Epoch : 21, Loss: 0.07088935375213623\n",
      "Epoch : 21, Loss: 0.05534335970878601\n",
      "Epoch : 21, Loss: 0.052600737661123276\n",
      "Epoch : 21, Loss: 0.0033658358734101057\n",
      "Epoch : 21, Loss: 0.024678818881511688\n",
      "Epoch : 21, Loss: 0.03004293143749237\n",
      "Epoch : 21, Loss: 0.015251348726451397\n",
      "Epoch : 21, Loss: 0.01407864224165678\n",
      "Epoch : 21, Loss: 0.031734973192214966\n",
      "Epoch : 21, Loss: 0.02907811850309372\n",
      "Epoch : 21, Loss: 0.007608720101416111\n",
      "Epoch : 21, Loss: 0.02896341308951378\n",
      "Epoch : 21, Loss: 0.023084798827767372\n",
      "Epoch : 21, Loss: 0.03098047897219658\n",
      "Epoch : 21, Loss: 0.013755287043750286\n",
      "Epoch : 21, Loss: 0.0263786893337965\n",
      "Epoch : 21, Loss: 0.009268270805478096\n",
      "Epoch : 21, Loss: 0.03472321107983589\n",
      "Epoch : 21, Loss: 0.058649174869060516\n",
      "Epoch : 21, Loss: 0.03020181506872177\n",
      "Epoch : 21, Loss: 0.015851320698857307\n",
      "Epoch : 21, Loss: 0.014696630649268627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2200fecf8ed24bd5a3c11514eb539847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7705031379640463\n",
      "F1 Score (Micro) = 0.7908549783549783\n",
      "F1 Score (Macro) = 0.769057189028511\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacc92e43ad84873be145d52f6aea46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22, Loss: 0.008879907429218292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22, Loss: 0.02320423536002636\n",
      "Epoch : 22, Loss: 0.010823420248925686\n",
      "Epoch : 22, Loss: 0.005807909183204174\n",
      "Epoch : 22, Loss: 0.010908255353569984\n",
      "Epoch : 22, Loss: 0.017020925879478455\n",
      "Epoch : 22, Loss: 0.019490087404847145\n",
      "Epoch : 22, Loss: 0.00678700115531683\n",
      "Epoch : 22, Loss: 0.019319351762533188\n",
      "Epoch : 22, Loss: 0.017904609441757202\n",
      "Epoch : 22, Loss: 0.019298693165183067\n",
      "Epoch : 22, Loss: 0.022234739735722542\n",
      "Epoch : 22, Loss: 0.018940791487693787\n",
      "Epoch : 22, Loss: 0.007423967123031616\n",
      "Epoch : 22, Loss: 0.010653453879058361\n",
      "Epoch : 22, Loss: 0.03652329370379448\n",
      "Epoch : 22, Loss: 0.013246698305010796\n",
      "Epoch : 22, Loss: 0.0039372011087834835\n",
      "Epoch : 22, Loss: 0.014759152196347713\n",
      "Epoch : 22, Loss: 0.019731907173991203\n",
      "Epoch : 22, Loss: 0.022914141416549683\n",
      "Epoch : 22, Loss: 0.006950589828193188\n",
      "Epoch : 22, Loss: 0.08568057417869568\n",
      "Epoch : 22, Loss: 0.05198335275053978\n",
      "Epoch : 22, Loss: 0.006247573997825384\n",
      "Epoch : 22, Loss: 0.0510062538087368\n",
      "Epoch : 22, Loss: 0.0420001856982708\n",
      "Epoch : 22, Loss: 0.008276909589767456\n",
      "Epoch : 22, Loss: 0.009233241900801659\n",
      "Epoch : 22, Loss: 0.029560117051005363\n",
      "Epoch : 22, Loss: 0.027557726949453354\n",
      "Epoch : 22, Loss: 0.005934085696935654\n",
      "Epoch : 22, Loss: 0.029043816030025482\n",
      "Epoch : 22, Loss: 0.014477178454399109\n",
      "Epoch : 22, Loss: 0.005029363092035055\n",
      "Epoch : 22, Loss: 0.027738355100154877\n",
      "Epoch : 22, Loss: 0.011821329593658447\n",
      "Epoch : 22, Loss: 0.004866156727075577\n",
      "Epoch : 22, Loss: 0.04027773439884186\n",
      "Epoch : 22, Loss: 0.005450246389955282\n",
      "Epoch : 22, Loss: 0.06269900500774384\n",
      "Epoch : 22, Loss: 0.04446929693222046\n",
      "Epoch : 22, Loss: 0.004404951818287373\n",
      "Epoch : 22, Loss: 0.017141688615083694\n",
      "Epoch : 22, Loss: 0.005665128584951162\n",
      "Epoch : 22, Loss: 0.00793673750013113\n",
      "Epoch : 22, Loss: 0.01738513447344303\n",
      "Epoch : 22, Loss: 0.022715328261256218\n",
      "Epoch : 22, Loss: 0.010978682897984982\n",
      "Epoch : 22, Loss: 0.04031174257397652\n",
      "Epoch : 22, Loss: 0.03840508311986923\n",
      "Epoch : 22, Loss: 0.09173548221588135\n",
      "Epoch : 22, Loss: 0.010221704840660095\n",
      "Epoch : 22, Loss: 0.03167257457971573\n",
      "Epoch : 22, Loss: 0.010321679525077343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0bfe694ca4418aba9edb0ada4afaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7684288905435592\n",
      "F1 Score (Micro) = 0.7883923012371077\n",
      "F1 Score (Macro) = 0.7709280582414348\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5a95959d1f4caa8c1cd47e2d2529d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23, Loss: 0.06464806944131851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23, Loss: 0.003732625162228942\n",
      "Epoch : 23, Loss: 0.01199245359748602\n",
      "Epoch : 23, Loss: 0.012273970060050488\n",
      "Epoch : 23, Loss: 0.007918069139122963\n",
      "Epoch : 23, Loss: 0.006456069648265839\n",
      "Epoch : 23, Loss: 0.023291245102882385\n",
      "Epoch : 23, Loss: 0.006663007661700249\n",
      "Epoch : 23, Loss: 0.02390640787780285\n",
      "Epoch : 23, Loss: 0.01521428395062685\n",
      "Epoch : 23, Loss: 0.002555853221565485\n",
      "Epoch : 23, Loss: 0.005357197020202875\n",
      "Epoch : 23, Loss: 0.01086773257702589\n",
      "Epoch : 23, Loss: 0.020345475524663925\n",
      "Epoch : 23, Loss: 0.04210612177848816\n",
      "Epoch : 23, Loss: 0.03068768046796322\n",
      "Epoch : 23, Loss: 0.059896063059568405\n",
      "Epoch : 23, Loss: 0.04912116006016731\n",
      "Epoch : 23, Loss: 0.01824238896369934\n",
      "Epoch : 23, Loss: 0.04937826469540596\n",
      "Epoch : 23, Loss: 0.05260169506072998\n",
      "Epoch : 23, Loss: 0.009291899390518665\n",
      "Epoch : 23, Loss: 0.007312089204788208\n",
      "Epoch : 23, Loss: 0.043411869555711746\n",
      "Epoch : 23, Loss: 0.053917571902275085\n",
      "Epoch : 23, Loss: 0.01626327633857727\n",
      "Epoch : 23, Loss: 0.022408103570342064\n",
      "Epoch : 23, Loss: 0.0067391409538686275\n",
      "Epoch : 23, Loss: 0.008834983222186565\n",
      "Epoch : 23, Loss: 0.050361212342977524\n",
      "Epoch : 23, Loss: 0.06165172904729843\n",
      "Epoch : 23, Loss: 0.03485012426972389\n",
      "Epoch : 23, Loss: 0.005523053929209709\n",
      "Epoch : 23, Loss: 0.008279618807137012\n",
      "Epoch : 23, Loss: 0.00642884336411953\n",
      "Epoch : 23, Loss: 0.020817341282963753\n",
      "Epoch : 23, Loss: 0.080785371363163\n",
      "Epoch : 23, Loss: 0.033408064395189285\n",
      "Epoch : 23, Loss: 0.02372610569000244\n",
      "Epoch : 23, Loss: 0.06501678377389908\n",
      "Epoch : 23, Loss: 0.029197828844189644\n",
      "Epoch : 23, Loss: 0.012544306926429272\n",
      "Epoch : 23, Loss: 0.011594759300351143\n",
      "Epoch : 23, Loss: 0.007325794547796249\n",
      "Epoch : 23, Loss: 0.03730890154838562\n",
      "Epoch : 23, Loss: 0.06314056366682053\n",
      "Epoch : 23, Loss: 0.0387825109064579\n",
      "Epoch : 23, Loss: 0.055606432259082794\n",
      "Epoch : 23, Loss: 0.062493953853845596\n",
      "Epoch : 23, Loss: 0.024332066997885704\n",
      "Epoch : 23, Loss: 0.020123088732361794\n",
      "Epoch : 23, Loss: 0.001873702509328723\n",
      "Epoch : 23, Loss: 0.03562222421169281\n",
      "Epoch : 23, Loss: 0.07275796681642532\n",
      "Epoch : 23, Loss: 0.0055514052510261536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b6efb5c9d44c27bc8c52ee1adebfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7734283586852463\n",
      "F1 Score (Micro) = 0.790870831984461\n",
      "F1 Score (Macro) = 0.7708006569476052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1633be503b41f78015d552cf72f729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24, Loss: 0.02068786881864071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24, Loss: 0.021407566964626312\n",
      "Epoch : 24, Loss: 0.03436041995882988\n",
      "Epoch : 24, Loss: 0.0022189696319401264\n",
      "Epoch : 24, Loss: 0.014241778291761875\n",
      "Epoch : 24, Loss: 0.006830647587776184\n",
      "Epoch : 24, Loss: 0.01965145207941532\n",
      "Epoch : 24, Loss: 0.03985944017767906\n",
      "Epoch : 24, Loss: 0.02500320039689541\n",
      "Epoch : 24, Loss: 0.06530039012432098\n",
      "Epoch : 24, Loss: 0.007552648428827524\n",
      "Epoch : 24, Loss: 0.013031674548983574\n",
      "Epoch : 24, Loss: 0.005399348214268684\n",
      "Epoch : 24, Loss: 0.01660533994436264\n",
      "Epoch : 24, Loss: 0.009605887345969677\n",
      "Epoch : 24, Loss: 0.017212167382240295\n",
      "Epoch : 24, Loss: 0.04662759229540825\n",
      "Epoch : 24, Loss: 0.004193859174847603\n",
      "Epoch : 24, Loss: 0.0035156821832060814\n",
      "Epoch : 24, Loss: 0.0691632404923439\n",
      "Epoch : 24, Loss: 0.0033800224773585796\n",
      "Epoch : 24, Loss: 0.0051822662353515625\n",
      "Epoch : 24, Loss: 0.013903316110372543\n",
      "Epoch : 24, Loss: 0.08070535212755203\n",
      "Epoch : 24, Loss: 0.009667274542152882\n",
      "Epoch : 24, Loss: 0.003110511926934123\n",
      "Epoch : 24, Loss: 0.021437643095850945\n",
      "Epoch : 24, Loss: 0.026571594178676605\n",
      "Epoch : 24, Loss: 0.00366494944319129\n",
      "Epoch : 24, Loss: 0.003891080617904663\n",
      "Epoch : 24, Loss: 0.049047719687223434\n",
      "Epoch : 24, Loss: 0.052630480378866196\n",
      "Epoch : 24, Loss: 0.006390800233930349\n",
      "Epoch : 24, Loss: 0.004618887323886156\n",
      "Epoch : 24, Loss: 0.004763825796544552\n",
      "Epoch : 24, Loss: 0.028760354965925217\n",
      "Epoch : 24, Loss: 0.030032478272914886\n",
      "Epoch : 24, Loss: 0.008313005790114403\n",
      "Epoch : 24, Loss: 0.006778363604098558\n",
      "Epoch : 24, Loss: 0.03826100379228592\n",
      "Epoch : 24, Loss: 0.020635360851883888\n",
      "Epoch : 24, Loss: 0.04396378621459007\n",
      "Epoch : 24, Loss: 0.002934388117864728\n",
      "Epoch : 24, Loss: 0.013432806357741356\n",
      "Epoch : 24, Loss: 0.023377804085612297\n",
      "Epoch : 24, Loss: 0.003906498197466135\n",
      "Epoch : 24, Loss: 0.0888846293091774\n",
      "Epoch : 24, Loss: 0.014434262178838253\n",
      "Epoch : 24, Loss: 0.01988833397626877\n",
      "Epoch : 24, Loss: 0.0023460437078028917\n",
      "Epoch : 24, Loss: 0.00928837526589632\n",
      "Epoch : 24, Loss: 0.009286034852266312\n",
      "Epoch : 24, Loss: 0.0169823057949543\n",
      "Epoch : 24, Loss: 0.00413653114810586\n",
      "Epoch : 24, Loss: 0.00619494030252099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cadbc02d1b42f0b317792534870a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7724710137219445\n",
      "F1 Score (Micro) = 0.7909235625826295\n",
      "F1 Score (Macro) = 0.7696959039883271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51cc18c039047fcb05719feb5cff10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25, Loss: 0.012508046813309193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25, Loss: 0.05757713317871094\n",
      "Epoch : 25, Loss: 0.01607818529009819\n",
      "Epoch : 25, Loss: 0.0054402402602136135\n",
      "Epoch : 25, Loss: 0.02622823975980282\n",
      "Epoch : 25, Loss: 0.029664283618330956\n",
      "Epoch : 25, Loss: 0.04660382121801376\n",
      "Epoch : 25, Loss: 0.005463824607431889\n",
      "Epoch : 25, Loss: 0.02050703763961792\n",
      "Epoch : 25, Loss: 0.06620975583791733\n",
      "Epoch : 25, Loss: 0.06359424442052841\n",
      "Epoch : 25, Loss: 0.025863908231258392\n",
      "Epoch : 25, Loss: 0.026616696268320084\n",
      "Epoch : 25, Loss: 0.006068933755159378\n",
      "Epoch : 25, Loss: 0.014378349296748638\n",
      "Epoch : 25, Loss: 0.004326831549406052\n",
      "Epoch : 25, Loss: 0.007195901125669479\n",
      "Epoch : 25, Loss: 0.042458388954401016\n",
      "Epoch : 25, Loss: 0.008630940690636635\n",
      "Epoch : 25, Loss: 0.010440482757985592\n",
      "Epoch : 25, Loss: 0.01668589934706688\n",
      "Epoch : 25, Loss: 0.02152886986732483\n",
      "Epoch : 25, Loss: 0.07456640154123306\n",
      "Epoch : 25, Loss: 0.01566828042268753\n",
      "Epoch : 25, Loss: 0.11527451872825623\n",
      "Epoch : 25, Loss: 0.06502152979373932\n",
      "Epoch : 25, Loss: 0.0074772401712834835\n",
      "Epoch : 25, Loss: 0.012835576198995113\n",
      "Epoch : 25, Loss: 0.017645839601755142\n",
      "Epoch : 25, Loss: 0.05665929242968559\n",
      "Epoch : 25, Loss: 0.04944074898958206\n",
      "Epoch : 25, Loss: 0.030799010768532753\n",
      "Epoch : 25, Loss: 0.0030737195629626513\n",
      "Epoch : 25, Loss: 0.0050340876914560795\n",
      "Epoch : 25, Loss: 0.019204264506697655\n",
      "Epoch : 25, Loss: 0.012386681511998177\n",
      "Epoch : 25, Loss: 0.03765677660703659\n",
      "Epoch : 25, Loss: 0.03689713031053543\n",
      "Epoch : 25, Loss: 0.003966331481933594\n",
      "Epoch : 25, Loss: 0.005085930228233337\n",
      "Epoch : 25, Loss: 0.006397786550223827\n",
      "Epoch : 25, Loss: 0.08012028783559799\n",
      "Epoch : 25, Loss: 0.01796776056289673\n",
      "Epoch : 25, Loss: 0.031492091715335846\n",
      "Epoch : 25, Loss: 0.0258195698261261\n",
      "Epoch : 25, Loss: 0.002701029647141695\n",
      "Epoch : 25, Loss: 0.006946905516088009\n",
      "Epoch : 25, Loss: 0.037585463374853134\n",
      "Epoch : 25, Loss: 0.02077268250286579\n",
      "Epoch : 25, Loss: 0.017836783081293106\n",
      "Epoch : 25, Loss: 0.04192173853516579\n",
      "Epoch : 25, Loss: 0.006392108742147684\n",
      "Epoch : 25, Loss: 0.03949381783604622\n",
      "Epoch : 25, Loss: 0.004795476794242859\n",
      "Epoch : 25, Loss: 0.028602514415979385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d329da93dbd846389476f84254ab2e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7731624295287736\n",
      "F1 Score (Micro) = 0.7924497731691509\n",
      "F1 Score (Macro) = 0.7725287327844087\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09cf7817e9941c38ec8a8405c691c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26, Loss: 0.014495424926280975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26, Loss: 0.0679510235786438\n",
      "Epoch : 26, Loss: 0.004226302728056908\n",
      "Epoch : 26, Loss: 0.015367286279797554\n",
      "Epoch : 26, Loss: 0.03693462535738945\n",
      "Epoch : 26, Loss: 0.010943107306957245\n",
      "Epoch : 26, Loss: 0.03989504650235176\n",
      "Epoch : 26, Loss: 0.04926104098558426\n",
      "Epoch : 26, Loss: 0.009035201743245125\n",
      "Epoch : 26, Loss: 0.0072721815668046474\n",
      "Epoch : 26, Loss: 0.0055098882876336575\n",
      "Epoch : 26, Loss: 0.0056623611599206924\n",
      "Epoch : 26, Loss: 0.08528701215982437\n",
      "Epoch : 26, Loss: 0.029324911534786224\n",
      "Epoch : 26, Loss: 0.013963394798338413\n",
      "Epoch : 26, Loss: 0.010511555708944798\n",
      "Epoch : 26, Loss: 0.01014647912234068\n",
      "Epoch : 26, Loss: 0.03293406963348389\n",
      "Epoch : 26, Loss: 0.006993502378463745\n",
      "Epoch : 26, Loss: 0.004745327867567539\n",
      "Epoch : 26, Loss: 0.024759093299508095\n",
      "Epoch : 26, Loss: 0.004205372184514999\n",
      "Epoch : 26, Loss: 0.002498169196769595\n",
      "Epoch : 26, Loss: 0.020091526210308075\n",
      "Epoch : 26, Loss: 0.03596457839012146\n",
      "Epoch : 26, Loss: 0.033242784440517426\n",
      "Epoch : 26, Loss: 0.05260416865348816\n",
      "Epoch : 26, Loss: 0.032256118953228\n",
      "Epoch : 26, Loss: 0.030408423393964767\n",
      "Epoch : 26, Loss: 0.016395607963204384\n",
      "Epoch : 26, Loss: 0.004568405449390411\n",
      "Epoch : 26, Loss: 0.003574939677491784\n",
      "Epoch : 26, Loss: 0.014531930908560753\n",
      "Epoch : 26, Loss: 0.004772749729454517\n",
      "Epoch : 26, Loss: 0.0066423858515918255\n",
      "Epoch : 26, Loss: 0.03878706693649292\n",
      "Epoch : 26, Loss: 0.018267404288053513\n",
      "Epoch : 26, Loss: 0.015820441767573357\n",
      "Epoch : 26, Loss: 0.003098277607932687\n",
      "Epoch : 26, Loss: 0.009485368616878986\n",
      "Epoch : 26, Loss: 0.047130949795246124\n",
      "Epoch : 26, Loss: 0.005804994609206915\n",
      "Epoch : 26, Loss: 0.055956870317459106\n",
      "Epoch : 26, Loss: 0.05143655464053154\n",
      "Epoch : 26, Loss: 0.014300839975476265\n",
      "Epoch : 26, Loss: 0.0030787524301558733\n",
      "Epoch : 26, Loss: 0.00489343935623765\n",
      "Epoch : 26, Loss: 0.012256573885679245\n",
      "Epoch : 26, Loss: 0.0016036955639719963\n",
      "Epoch : 26, Loss: 0.04583415389060974\n",
      "Epoch : 26, Loss: 0.008637269027531147\n",
      "Epoch : 26, Loss: 0.019283857196569443\n",
      "Epoch : 26, Loss: 0.009606820531189442\n",
      "Epoch : 26, Loss: 0.023414483293890953\n",
      "Epoch : 26, Loss: 0.07504760473966599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95ae1cf679a42f39b39e4ad6258524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7746516328050207\n",
      "F1 Score (Micro) = 0.7935384532267215\n",
      "F1 Score (Macro) = 0.7715359309535718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3aaa9be8555457a82986c4824c3bbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27, Loss: 0.00877063162624836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27, Loss: 0.04534376785159111\n",
      "Epoch : 27, Loss: 0.021153971552848816\n",
      "Epoch : 27, Loss: 0.010734508745372295\n",
      "Epoch : 27, Loss: 0.015536139719188213\n",
      "Epoch : 27, Loss: 0.036952197551727295\n",
      "Epoch : 27, Loss: 0.005573919042944908\n",
      "Epoch : 27, Loss: 0.07177478820085526\n",
      "Epoch : 27, Loss: 0.003259277669712901\n",
      "Epoch : 27, Loss: 0.01771397888660431\n",
      "Epoch : 27, Loss: 0.012184505350887775\n",
      "Epoch : 27, Loss: 0.048105429857969284\n",
      "Epoch : 27, Loss: 0.006510721053928137\n",
      "Epoch : 27, Loss: 0.010128243826329708\n",
      "Epoch : 27, Loss: 0.01762528158724308\n",
      "Epoch : 27, Loss: 0.0684477910399437\n",
      "Epoch : 27, Loss: 0.008702076971530914\n",
      "Epoch : 27, Loss: 0.03979158774018288\n",
      "Epoch : 27, Loss: 0.05152587592601776\n",
      "Epoch : 27, Loss: 0.025229627266526222\n",
      "Epoch : 27, Loss: 0.022845527157187462\n",
      "Epoch : 27, Loss: 0.020938806235790253\n",
      "Epoch : 27, Loss: 0.0034156902693212032\n",
      "Epoch : 27, Loss: 0.03221505880355835\n",
      "Epoch : 27, Loss: 0.032042261213064194\n",
      "Epoch : 27, Loss: 0.0139194680377841\n",
      "Epoch : 27, Loss: 0.00541822100058198\n",
      "Epoch : 27, Loss: 0.010996997356414795\n",
      "Epoch : 27, Loss: 0.007941758260130882\n",
      "Epoch : 27, Loss: 0.016826359555125237\n",
      "Epoch : 27, Loss: 0.05347049981355667\n",
      "Epoch : 27, Loss: 0.007142082788050175\n",
      "Epoch : 27, Loss: 0.00988586712628603\n",
      "Epoch : 27, Loss: 0.005928877741098404\n",
      "Epoch : 27, Loss: 0.04496397078037262\n",
      "Epoch : 27, Loss: 0.015724673867225647\n",
      "Epoch : 27, Loss: 0.004466937389224768\n",
      "Epoch : 27, Loss: 0.030147777870297432\n",
      "Epoch : 27, Loss: 0.014319689944386482\n",
      "Epoch : 27, Loss: 0.022934090346097946\n",
      "Epoch : 27, Loss: 0.007272718008607626\n",
      "Epoch : 27, Loss: 0.020079053938388824\n",
      "Epoch : 27, Loss: 0.02897818386554718\n",
      "Epoch : 27, Loss: 0.029520200565457344\n",
      "Epoch : 27, Loss: 0.00440966198220849\n",
      "Epoch : 27, Loss: 0.014385536313056946\n",
      "Epoch : 27, Loss: 0.0022273724898695946\n",
      "Epoch : 27, Loss: 0.019302476197481155\n",
      "Epoch : 27, Loss: 0.0059292553924024105\n",
      "Epoch : 27, Loss: 0.01961738057434559\n",
      "Epoch : 27, Loss: 0.007660701405256987\n",
      "Epoch : 27, Loss: 0.013881340622901917\n",
      "Epoch : 27, Loss: 0.03161930292844772\n",
      "Epoch : 27, Loss: 0.011930509470403194\n",
      "Epoch : 27, Loss: 0.0030391362961381674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c922baa12d5406eb9eb411495dd5d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7721518987341772\n",
      "F1 Score (Micro) = 0.7903881899733304\n",
      "F1 Score (Macro) = 0.7713353477357404\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09fff3331ae24b3eacece646d69a93e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28, Loss: 0.007700883783400059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28, Loss: 0.028593145310878754\n",
      "Epoch : 28, Loss: 0.0034190898295491934\n",
      "Epoch : 28, Loss: 0.01691899262368679\n",
      "Epoch : 28, Loss: 0.017496198415756226\n",
      "Epoch : 28, Loss: 0.02570452354848385\n",
      "Epoch : 28, Loss: 0.00498375715687871\n",
      "Epoch : 28, Loss: 0.03173556551337242\n",
      "Epoch : 28, Loss: 0.07850277423858643\n",
      "Epoch : 28, Loss: 0.01344856433570385\n",
      "Epoch : 28, Loss: 0.0027128495275974274\n",
      "Epoch : 28, Loss: 0.05452563613653183\n",
      "Epoch : 28, Loss: 0.019353942945599556\n",
      "Epoch : 28, Loss: 0.009525460191071033\n",
      "Epoch : 28, Loss: 0.07107917219400406\n",
      "Epoch : 28, Loss: 0.02116375043988228\n",
      "Epoch : 28, Loss: 0.0020738341845571995\n",
      "Epoch : 28, Loss: 0.0600331611931324\n",
      "Epoch : 28, Loss: 0.005308655556291342\n",
      "Epoch : 28, Loss: 0.010873387567698956\n",
      "Epoch : 28, Loss: 0.04004121199250221\n",
      "Epoch : 28, Loss: 0.0152351725846529\n",
      "Epoch : 28, Loss: 0.009878050535917282\n",
      "Epoch : 28, Loss: 0.021450402215123177\n",
      "Epoch : 28, Loss: 0.018653273582458496\n",
      "Epoch : 28, Loss: 0.004803672432899475\n",
      "Epoch : 28, Loss: 0.03509005904197693\n",
      "Epoch : 28, Loss: 0.0361102893948555\n",
      "Epoch : 28, Loss: 0.004172451328486204\n",
      "Epoch : 28, Loss: 0.008746320381760597\n",
      "Epoch : 28, Loss: 0.042741309851408005\n",
      "Epoch : 28, Loss: 0.015367697924375534\n",
      "Epoch : 28, Loss: 0.01463557593524456\n",
      "Epoch : 28, Loss: 0.04267013072967529\n",
      "Epoch : 28, Loss: 0.008229048922657967\n",
      "Epoch : 28, Loss: 0.04665958508849144\n",
      "Epoch : 28, Loss: 0.010421009734272957\n",
      "Epoch : 28, Loss: 0.044864486902952194\n",
      "Epoch : 28, Loss: 0.06678150594234467\n",
      "Epoch : 28, Loss: 0.006052195560187101\n",
      "Epoch : 28, Loss: 0.013414205983281136\n",
      "Epoch : 28, Loss: 0.021770527586340904\n",
      "Epoch : 28, Loss: 0.003862748621031642\n",
      "Epoch : 28, Loss: 0.011300462298095226\n",
      "Epoch : 28, Loss: 0.030006222426891327\n",
      "Epoch : 28, Loss: 0.07242456823587418\n",
      "Epoch : 28, Loss: 0.009971226565539837\n",
      "Epoch : 28, Loss: 0.004522338509559631\n",
      "Epoch : 28, Loss: 0.009915130212903023\n",
      "Epoch : 28, Loss: 0.053101155906915665\n",
      "Epoch : 28, Loss: 0.04980117082595825\n",
      "Epoch : 28, Loss: 0.0022337601985782385\n",
      "Epoch : 28, Loss: 0.017796963453292847\n",
      "Epoch : 28, Loss: 0.060645513236522675\n",
      "Epoch : 28, Loss: 0.01913970522582531\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f1de46b20d427d9bfb4da2a45a8a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7764599510690352\n",
      "F1 Score (Micro) = 0.7939511563965712\n",
      "F1 Score (Macro) = 0.7708736741848774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28c32c9dc004bc89fa01e063d9a73c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29, Loss: 0.0052626412361860275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29, Loss: 0.0031354522798210382\n",
      "Epoch : 29, Loss: 0.053498100489377975\n",
      "Epoch : 29, Loss: 0.025534169748425484\n",
      "Epoch : 29, Loss: 0.0015832858625799417\n",
      "Epoch : 29, Loss: 0.013857810758054256\n",
      "Epoch : 29, Loss: 0.005263825412839651\n",
      "Epoch : 29, Loss: 0.05126305669546127\n",
      "Epoch : 29, Loss: 0.006198142189532518\n",
      "Epoch : 29, Loss: 0.018132701516151428\n",
      "Epoch : 29, Loss: 0.003210870549082756\n",
      "Epoch : 29, Loss: 0.014960629865527153\n",
      "Epoch : 29, Loss: 0.048801880329847336\n",
      "Epoch : 29, Loss: 0.004973267205059528\n",
      "Epoch : 29, Loss: 0.03718138486146927\n",
      "Epoch : 29, Loss: 0.0025313813239336014\n",
      "Epoch : 29, Loss: 0.03009159304201603\n",
      "Epoch : 29, Loss: 0.007633702363818884\n",
      "Epoch : 29, Loss: 0.031042929738759995\n",
      "Epoch : 29, Loss: 0.026680169627070427\n",
      "Epoch : 29, Loss: 0.0026581494603306055\n",
      "Epoch : 29, Loss: 0.003589618019759655\n",
      "Epoch : 29, Loss: 0.010899747721850872\n",
      "Epoch : 29, Loss: 0.00653076171875\n",
      "Epoch : 29, Loss: 0.08562634885311127\n",
      "Epoch : 29, Loss: 0.008838595822453499\n",
      "Epoch : 29, Loss: 0.036549162119627\n",
      "Epoch : 29, Loss: 0.0505005344748497\n",
      "Epoch : 29, Loss: 0.0026803200598806143\n",
      "Epoch : 29, Loss: 0.008877821266651154\n",
      "Epoch : 29, Loss: 0.02247471734881401\n",
      "Epoch : 29, Loss: 0.016988907009363174\n",
      "Epoch : 29, Loss: 0.008668579161167145\n",
      "Epoch : 29, Loss: 0.03272408992052078\n",
      "Epoch : 29, Loss: 0.002365241991356015\n",
      "Epoch : 29, Loss: 0.011725959368050098\n",
      "Epoch : 29, Loss: 0.032919175922870636\n",
      "Epoch : 29, Loss: 0.00581338768824935\n",
      "Epoch : 29, Loss: 0.009999548085033894\n",
      "Epoch : 29, Loss: 0.022510657086968422\n",
      "Epoch : 29, Loss: 0.022743210196495056\n",
      "Epoch : 29, Loss: 0.027605172246694565\n",
      "Epoch : 29, Loss: 0.04837421700358391\n",
      "Epoch : 29, Loss: 0.09599597007036209\n",
      "Epoch : 29, Loss: 0.01873842068016529\n",
      "Epoch : 29, Loss: 0.01334918662905693\n",
      "Epoch : 29, Loss: 0.05951779708266258\n",
      "Epoch : 29, Loss: 0.04055760055780411\n",
      "Epoch : 29, Loss: 0.003272710368037224\n",
      "Epoch : 29, Loss: 0.02022513933479786\n",
      "Epoch : 29, Loss: 0.008692571893334389\n",
      "Epoch : 29, Loss: 0.023468350991606712\n",
      "Epoch : 29, Loss: 0.010226629674434662\n",
      "Epoch : 29, Loss: 0.006503536831587553\n",
      "Epoch : 29, Loss: 0.043064165860414505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb07bc154bd3434f9c2429e20452c204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.776832251888097\n",
      "F1 Score (Micro) = 0.7928713724223334\n",
      "F1 Score (Macro) = 0.7706064931098272\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    output = train(epoch)\n",
    "    # evaluate\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input, tokenizer, model, device):\n",
    "    ''' GOAL OF THIS FUNCTION: \n",
    "    This function takes in any given string and converts it into a tokenized version that can be run through the model. '''\n",
    "\n",
    "    input = \" \".join(input.split())\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        input,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=175,\n",
    "        pad_to_max_length=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    \n",
    "    ids = torch.tensor(inputs['input_ids'], dtype=torch.long).to(device, dtype = torch.long)\n",
    "    mask = torch.tensor(inputs['attention_mask'], dtype=torch.long).to(device, dtype= torch.long)\n",
    "    token_type_ids = torch.tensor(inputs['token_type_ids'], dtype=torch.long).to(device, dtype= torch.long)\n",
    "\n",
    "    output = model(ids.unsqueeze(0), mask.unsqueeze(0), token_type_ids.unsqueeze(0))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predictions with the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# To predict, the model is looking for the ids, mask and token_type_ids. Which means whatever we input must be run through the tokenizer first. \n",
    "input='Data Scientist'\n",
    "output = predict(input, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output.cpu().detach().numpy().tolist(), columns=label_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>23</th>\n",
       "      <th>25</th>\n",
       "      <th>27</th>\n",
       "      <th>29</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>37</th>\n",
       "      <th>39</th>\n",
       "      <th>41</th>\n",
       "      <th>43</th>\n",
       "      <th>45</th>\n",
       "      <th>47</th>\n",
       "      <th>49</th>\n",
       "      <th>51</th>\n",
       "      <th>53</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.454539</td>\n",
       "      <td>-6.445076</td>\n",
       "      <td>-0.202713</td>\n",
       "      <td>-5.343482</td>\n",
       "      <td>0.482879</td>\n",
       "      <td>-6.678531</td>\n",
       "      <td>-8.999181</td>\n",
       "      <td>-7.400536</td>\n",
       "      <td>-7.201194</td>\n",
       "      <td>-6.639618</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.614067</td>\n",
       "      <td>-7.407125</td>\n",
       "      <td>-8.344387</td>\n",
       "      <td>-8.23388</td>\n",
       "      <td>-6.436518</td>\n",
       "      <td>-7.297492</td>\n",
       "      <td>-7.321807</td>\n",
       "      <td>-6.37388</td>\n",
       "      <td>-6.417892</td>\n",
       "      <td>-7.336663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         11        13        15        17        19        21        23   \n",
       "0 -7.454539 -6.445076 -0.202713 -5.343482  0.482879 -6.678531 -8.999181  \\\n",
       "\n",
       "         25        27        29  ...        35        37        39       41   \n",
       "0 -7.400536 -7.201194 -6.639618  ... -7.614067 -7.407125 -8.344387 -8.23388  \\\n",
       "\n",
       "         43        45        47       49        51        53  \n",
       "0 -6.436518 -7.297492 -7.321807 -6.37388 -6.417892 -7.336663  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the prediction, which is the value with the highest value. \n",
    "output_df.idxmax(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model: \n",
    "torch.save(model, f'../Data/Models/ONET_Family_Model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING PART TWO\n",
    "Now we train a model that will predict the specific job that this title belongs too. This will have to be 22 indidvidual models that will run based on the group that is chosen. I'm a little worried that the performance will not be as strong in comparison of the main model given that the data for each major group is much smaller in comparison to the main dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.eval of BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=22, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../Data/Models/ONET_Family_Model\")\n",
    "model.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\.virtualenvs\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input='Data Engineer'\n",
    "output = predict(input, tokenizer, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output.cpu().detach().numpy().tolist(), columns=label_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.idxmax(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
