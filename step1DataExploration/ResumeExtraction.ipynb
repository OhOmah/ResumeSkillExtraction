{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PURPOSE OF THIS NOTEBOOK\n",
    "This is the base code to write the functions to extract the raw text from resumes and append to our dataframe. \n",
    "\n",
    "TODO: Take the functions into a .py folder and use it as a script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zaffa\\Documents\\Projects\\NLP Resume Skill Extraction\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Code to load in the pretrained model from hugging face. \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tkuye/skills-classifier\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"tkuye/skills-classifier\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The validation data. \n",
    "\n",
    "Since this dataset that I'm using to test does not have ONET codes attached to them, I would have to source another dataset that does. Thankfully ONET does have such data that I can use for training. For each ONET code there's common job names appended to them, I could use that data with the pretained model. That being said this creates some challenges. \n",
    "1. For obsure and odd job names that are not listed in the common job names will almost guarentee bad performance. Given that the goal is to prove that we can get generally good performance with publicly available data, this is something I'm willing to sacrifice if it means that it will work correctly at least 80% of the time. \n",
    "\n",
    "I have sourced a table with common names linked with each onet code. I can use this data on the pretrained model to see how it classifies each of the common names linked with ONET codes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
